{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e16727",
   "metadata": {},
   "source": [
    "# Final Project CompStats | Timo Haupt | SoSe 2021\n",
    "\n",
    "---\n",
    "\n",
    "# Performance of Causal Forests in Identifying Heterogeneous Treatment Effects\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bb2ddf",
   "metadata": {},
   "source": [
    "**Importing Packages:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89a0afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressMessages(library(grf))\n",
    "suppressMessages(library(FNN))\n",
    "suppressMessages(library(MASS))\n",
    "suppressMessages(library(foreign))\n",
    "suppressMessages(library(dplyr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93360557",
   "metadata": {},
   "source": [
    "**Importing Functions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad0ba9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "source(\"material/auxiliary.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42c2b22",
   "metadata": {},
   "source": [
    "## Structure\n",
    "\n",
    "[**1. Theoretical Discussion**](#theory)\n",
    "   * [Causal Tree](#tree)\n",
    "   * [Causal Forest](#forest)\n",
    "    \n",
    "[**2. Simulation Study**](#simulation)\n",
    "   * [Data Generating Process](#dgp)\n",
    "   * [Performance Measure](#performance)\n",
    "   * [Variations](#simstudy)\n",
    "\n",
    "[**3. Application**](#application)\n",
    "   * [Lalonde Data Set](#lalonde)\n",
    "   * [Causal Forest Estimations](#causalforest)\n",
    "\n",
    "[**4. Conclusion**](#conclusion)\n",
    "\n",
    "[**5. References**](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f454cb94",
   "metadata": {},
   "source": [
    "## 1.) Theoretical Discussion<a id=\"theory\"></a>\n",
    "\n",
    "This first section introduces how causal tree and causal forest estimation methods work, and describes how treatment estimation is conducted. The main problem in settings dealing with causality and inference is the missing counterfactual. Particularly in estimating treatment effects it's only possible to observe an individual with treatment, $Y_i^{(1)}$, or without treatment, $Y_i^{(0)}$, but never both. Therefore, we are in the Potential Outcome Framework where we \"posit the existence of potential outcomes $Y_i^{(1)}$ and $Y_i^{(0)}$ corresponding respectively to\n",
    "the response the $i$-th subject would have experienced with and without the treatment\" (Athey & Wager 2015).\n",
    "\n",
    "The causal forest estimation method tries to find these potential outcomes by some sort of matching in order to estimate the treatment effect \n",
    "$$\\tau(x) = \\mathbb{E}\\left[Y_i^{(1)} - Y_i^{(0)} \\mid X_i = x\\right]. $$\n",
    "\n",
    "One essential assumption we need to impose in order to theoretically justify the estimation method is unconfoundedness, i.e. \"treatment assignment $W_i$ is independent of the potential outcomes for $Y_i$ conditional on $X_i$\" (Athey & Wager 2015):\n",
    "\n",
    "$$\\left \\{Y_i^{(1)}, Y_i^{(0)} \\right \\} \\perp\\!\\!\\!\\perp W_i \\mid X_i $$\n",
    "\n",
    "The idea is that, if unconfoundedness holds, \"we can treat nearby observations in x-space as having come from a\n",
    "randomized experiment; thus, nearest-neighbor matching and other local methods will in general be consistent for $\\tau(x)$\" (Athey & Wager 2015)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec4f3e6",
   "metadata": {},
   "source": [
    "### Causal Tree<a id=\"tree\"></a>\n",
    "\n",
    "Before explaining how causal forests work, it is essential to describe a single causal tree, since the forest is made up of several thousand trees. Causal trees predict individual treatment effects rather than some output variable $Y$ in the setting of random trees. The estimation method is actually pretty similiar to the K-Nearest-Neighbor method, where based on some distance measure the K nearest observations are chosen and based on these neighbors a potential outcome is constructed. The causal tree also tries to find the most similiar observations, \"but now closeness is defined with respect to a decision tree, and the closest points to x are those that fall in the same leaf as it\" (Athey & Wager 2015). Therefore, one can check for every individual what are the predictions of observations that are in the same leaf and calculate a value for the potential outcome. \n",
    "\n",
    "**Treatment Effect Estimation**\n",
    "\n",
    "If we take some $x \\in R_k$ where $R_k$ is some leaf of the causal tree and define $N_k(w)$ as the number of observations in leaf $R_k$ with treatment status $w \\in \\{0,1\\}$, the Conditional Average Treatment Effect is then estimated \"based on the mean difference between the outcome levels of the treated and untreated units\" which are in the same leaf $R_k$ by \n",
    "\n",
    "$$ \\hat{\\tau}(x) = \\hat{\\tau}_{R_k} = \\frac{1}{N_k(1)} \\sum_{i \\in R_k(1)} Y_i-\\frac{1}{N_k(0)} \\sum_{i \\in R_k(0)} Y_i  . $$\n",
    "So, the causal forest does some sort of matching by recursively partitioning the predictor space and then matching treated and untreated observations that have fallen in the same leaf (see e.g. Hitsch & Misra 2018 and Athey & Wager 2015). Therefore, we can estimate for each observation some specific treatment effect based on it's characteristics $X_i$.\n",
    "\n",
    "**Splitting Rule & Honest Splitting**\n",
    "\n",
    "In the setting of causal trees \"the algorithm seeks to maximize the treatment effect heterogeneity across partitions at every tree-splitting step\" (Farbmacher et al. 2019). Therefore, it uses a splitting rule that maximizes \"the variance of the predicted treatment effects $\\hat{\\tau}(X_i)$ across the observations in the two new leaves\" (Hitsch & Misra 2018). In order to assure properties like consistency and asymptotic normality, Athey and Wager (2015) propose the necesity of the so called \"Honest Splitting Rule\". One way of achieving \"Honesty\" is the \"Double-Sample Tree\" which has been applied in all of the estimations in this project. \"Double-sample trees split the available training data into two parts: one half for estimating the desired response inside each leaf, and another half for placing splits\" (Athey & Wager 2015).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8780b85d",
   "metadata": {},
   "source": [
    "### Causal Forest<a id=\"forest\"></a>\n",
    "\n",
    "As noted the causal forest consists of multiple thousand single trees, where each tree estimates individual treatment effects for all observations in the sample. \"The forest then aggregates their predictions by averaging them: $\\hat{\\tau}(x) = \\frac{1}{B} \\sum_{b=1}^B \\hat{\\tau}_b(x)$\", where the default value is $B = 2000$. In the upcoming simulation study the default value has been chosen. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Advantages of Causal Forests**\n",
    "\n",
    "Similiar to random forests, the advantage of causal gorests over single causal trees is that \"a random sample of\n",
    "$m$ predictors is chosen as split candidates from the full set of $p$ predictors. The split is allowed to use only one of those m predictors\". Hence, this works as \"decorrelating the trees, thereby making the average of the resulting trees less variable and hence more reliable\" (Hastie et al. 2013). Furthermore, by aggregating $B$ single causal trees and therefore drawing $B$ random training and test samples (see section \"Honest Splitting\") it also \"helps to reduce variance and smooths sharp decision boundaries\" (Athey & Wager 2015).\n",
    "\n",
    "Compared to other matching estimation methods, \"the advantage of trees is that their leaves can be narrower along the directions where the signal is changing fast and wider along the other directions\" (Athey & Wager 2015). For this reason I will compare the performance of causal forests in settings where correlation between some regressors occurs (simulation study - Case 3) and where the number of regressors varies (Case 6), since Athey and Wager (2015) suppose \"a substantial increase in power when the dimension of the feature space is even moderately large\". I find a very good performance with correlation, but can't find an improvement in higher dimensions. To be fair, I have not compared the results to another matching estimation method, like KNN or Propensity Score Matching. Since we consider a trained causal forest, where only the most important variables from a first \"pilot run\" are considered, it seems plausible that the forest would outperform the other two methods by some kind of variable selection.    \n",
    "\n",
    "Since causal trees don't impose a structural functional form of the regressors, causal forests are \"a nonparametric estimation method, [and] in principle should be able to automatically detect any relevant interactions\" (Farbmacher et al. 2019). The performance of causal forests dealing with higher degree polynomials and interactions in the data generating process will be analyzed in Case 2 of the simulation study. It turns out that causal forests indeed seem to handle nonlinear interactions well, especially if treatment heterogeneity is not too complex. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c88d1",
   "metadata": {},
   "source": [
    "# 2.) Simulation Study<a id=\"simulation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33145bab",
   "metadata": {},
   "source": [
    "## Data Generating Process<a id=\"dgp\"></a>\n",
    "\n",
    "Note that the codes for the data generating process and the Monte Carlo simulation study can be found in the auxiliary-file. The variations in the treatment effect function $\\tau(x)$ and the DGP function are inspired by Athey & Wager (2015), Athey & Imbens (2015) and Powers et al. (2017). \n",
    "\n",
    "\n",
    "$$X_{i,1}, ..., X_{i,10} \\sim \\mathcal{N}(0,1)$$\n",
    "\n",
    "$$\\beta \\in [0.5,1]^{10}$$\n",
    "\n",
    "$$Prob(W_i=1) =0.5$$\n",
    "\n",
    "$$Y_i = X \\beta + \\tau(x_i)* W_i + \\epsilon_i $$\n",
    "\n",
    "$$\\epsilon_i \\sim \\mathcal{N}(0,\\,0.1)$$\n",
    "\n",
    "**Description**\n",
    "\n",
    "The specification above displays the basic setup of the data generating process. \n",
    "10 regressors are drawn from a standard normal distrubtion and all $\\beta$ are evenly divided between 0.5 and 1. \n",
    "The probability of being assigned to treatment is fixed at 50% for all observations. The individual error term is also drawn from a normal distribution with mean zero and standard deviation of 0.1.\n",
    "All changes and additions that have been made in the simulation study will be explained in greater detail as a description before each scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de094601",
   "metadata": {},
   "source": [
    "## Performance Measure<a id=\"performance\"></a>\n",
    "\n",
    "Eventhough the counterfactuals are never observed in real life data, we can take advantage of the data generating process in simulation studies where we explicitely calculate the true treatment effect for each observation. Therefore, as Athey & Wager (2015) proposed we can use the $MSE_{\\tau}$ as a measure in order to compare the performance of the causal forest in different settings. I calculated the Mean Squared Error of the treatment effect as follows\n",
    "$$MSE_{\\tau} = \\frac{1}{N} \\sum_{i=1}^N{\\left( \\tau_{i}-\\hat{\\tau}_{R_k}(X_i) \\right)^{2}} ,$$\n",
    "\n",
    "where $\\hat{\\tau}_{R_k}(X_i)$ are the estimated treatment effects for individuals in leaf $R_k$.\n",
    "Note that the $MSE_{\\tau}$ used in this Simulation Study differs slightly from the one proposed in the Athey and Imbens (2015) paper. They subtract $\\mathbb{E}[\\tau_i^2]$, but as they noted \"it does not affect how the criterion ranks estimators\", since $\\tau_i$ is explicitely calculated here and hence is not a random variable  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2661b0bd",
   "metadata": {},
   "source": [
    "## Monte Carlo Simulation Study - Variations<a id=\"simstudy\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559f2112",
   "metadata": {},
   "source": [
    "### Case 1 - Introduction of Treatment Effect Functions\n",
    "\n",
    "$(1)\\quad \\tau(x) = 0.2 $\n",
    "\n",
    "$(2)\\quad \\tau(x) = 0.1 + 0.1*\\mathbb{1}(x_1 > 0) + 0.1*\\mathbb{1}(x_2 > 0)$\n",
    "\n",
    "$(3)\\quad \\tau(x) = 0.1 + x_1*\\mathbb{1}(x_1 > 0) + x_2*\\mathbb{1}(x_2 > 0)$  \n",
    "\n",
    "$(4)\\quad \\tau(x) = 0.1 + \\sum_{i=1}^{4} x_i*\\mathbb{1}(x_i > 0) $\n",
    "\n",
    "$(5)\\quad \\tau(x) = 0.2 + x_1*x_2 $\n",
    "\n",
    "\n",
    "**Description & Result**\n",
    "\n",
    "Case 1 will be used as a benchmark where the basic setup is considered. The different treatment scenarios are depicted above. \n",
    "In the first treatment scenario $(1)$ there is only a single treatment effect independent of individuals' characteristics. Treatment scenario $(2)$ introduces some simple treatment effect heterogeneity, that is treatment effect increases if an individual has positive values in its' $X_1$ and $X_2$ characteristics respectively. Each positive value increases the magnitude of the treatment effect by the constant treatment effect of 0.1. \n",
    "In treatment scenario $(3)$ complexity of heterogeneity has been increased, such that the magnitude of treatment depends on the values of $X_1$ and $X_2$. So, treatment effect is even heterogeneous within $X_1$ and $X_2$. Higher positive values of these variables imply a higher treatment effect. \n",
    "Scenario $(4)$ adds two more regressors in the treatment effect function. \n",
    "Treatment scenario $(5)$ introduces an interaction term in $\\tau(x)$. Since $X$ are standard normally distributed, around half of the draws from $X_1$ and $X_2$ are negative, implying an even higher degree of treatment variation.\n",
    "\n",
    "It can be observed that the higher the number of observations, the smaller the Mean Squared Error. This holds true for all successive applications. This is theoretically justified, since with a higher number of observations the trees can perform more splits per tree without reaching the boundary of minimal observations per leaf. \n",
    "Interesting is that the $MSE_{\\tau}$ almost doesn't differ between homogeneous and a very simple heterogeneous treatment effect, $(1)$ and $(2)$. This result is quite remarkable and shows that Causal Forests seem to be quite good at matching observations with a simple heterogeneity structure. It should be noted that Powers et al. (2017) find some striking differences between scenarios 1 and 2 in their paper which come closest to my treatment scenarios $(1)$ and $(2)$. One reason might be that Powers et al. (2017) draw their regressors mixed from standard normal and bernoulli distributions.\n",
    "Since treatment scenarios $(3)$ to $(5)$ impose a higher degree of variation in individual treatment effects, it is obvious that the $MSE_{\\tau}$ are much higher compared to the previous scenarios. Even for a large sample the estimated $MSE_{\\tau}$ can't keep up. These results are consistent though with the ones from Table S1 (Appendix) in Athey and Imbens (2015)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22d3e10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c15c6671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Application</th><th scope=col>N = 100</th><th scope=col>N = 150</th><th scope=col>N = 250</th><th scope=col>N = 500</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Treatment 1</td><td>0.270      </td><td>0.140      </td><td>0.098      </td><td>0.059      </td></tr>\n",
       "\t<tr><td>Treatment 2</td><td>0.203      </td><td>0.152      </td><td>0.109      </td><td>0.081      </td></tr>\n",
       "\t<tr><td>Treatment 3</td><td>0.833      </td><td>0.698      </td><td>0.565      </td><td>0.382      </td></tr>\n",
       "\t<tr><td>Treatment 4</td><td>1.423      </td><td>1.271      </td><td>1.061      </td><td>0.784      </td></tr>\n",
       "\t<tr><td>Treatment 5</td><td>1.188      </td><td>1.167      </td><td>1.061      </td><td>0.996      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Application & N = 100 & N = 150 & N = 250 & N = 500\\\\\n",
       "\\hline\n",
       "\t Treatment 1 & 0.270       & 0.140       & 0.098       & 0.059      \\\\\n",
       "\t Treatment 2 & 0.203       & 0.152       & 0.109       & 0.081      \\\\\n",
       "\t Treatment 3 & 0.833       & 0.698       & 0.565       & 0.382      \\\\\n",
       "\t Treatment 4 & 1.423       & 1.271       & 1.061       & 0.784      \\\\\n",
       "\t Treatment 5 & 1.188       & 1.167       & 1.061       & 0.996      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Application | N = 100 | N = 150 | N = 250 | N = 500 |\n",
       "|---|---|---|---|---|\n",
       "| Treatment 1 | 0.270       | 0.140       | 0.098       | 0.059       |\n",
       "| Treatment 2 | 0.203       | 0.152       | 0.109       | 0.081       |\n",
       "| Treatment 3 | 0.833       | 0.698       | 0.565       | 0.382       |\n",
       "| Treatment 4 | 1.423       | 1.271       | 1.061       | 0.784       |\n",
       "| Treatment 5 | 1.188       | 1.167       | 1.061       | 0.996       |\n",
       "\n"
      ],
      "text/plain": [
       "  Application N = 100 N = 150 N = 250 N = 500\n",
       "1 Treatment 1 0.270   0.140   0.098   0.059  \n",
       "2 Treatment 2 0.203   0.152   0.109   0.081  \n",
       "3 Treatment 3 0.833   0.698   0.565   0.382  \n",
       "4 Treatment 4 1.423   1.271   1.061   0.784  \n",
       "5 Treatment 5 1.188   1.167   1.061   0.996  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simulation(p=10,numsim=100,regressors=\"nocorr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7a38e2",
   "metadata": {},
   "source": [
    "### Case 2 - Polynomials and Interactions added to DGP\n",
    "\n",
    "$(1) \\quad X_{i,9} = X_{i,1}^2 \\quad $ and $\\quad X_{i,10} = X_{i,2}^2$\n",
    "\n",
    "$(2) \\quad X_{i,2} = X_{i,1}^2$\n",
    "\n",
    "$(3) \\quad X_{i,10} = X_{i,1}*X_{i,2}$\n",
    "\n",
    "**Description & Result**\n",
    "\n",
    "In Case 2 different changes in the data generating process have been made. In scenario $(1)$ quadratic transformations of $X_1$ and $X_2$ have been added in the DGP function. Scenario $(2)$ differs in that the quadratic transformation of $X_1$ displaces the $X_2$ variable, implying that only $X_1$ and it's second degree polynomial determine treatment heterogeneity. $(3)$ depicts the scenario with an additional interaction term between $X_1$ and $X_2$ in the DGP.\n",
    "\n",
    "\n",
    "\n",
    "Causal forests seem to make pretty good treatment predictions compared to the benchark Case 1, with one exception. Since causal forests are a nonparametric method and therefore don't make explicit assumptions about the underlying functional form, this result seems to be consistent with the theoretical properties explained in part 1 of this paper.\n",
    "Adding the interaction term between $X_1$ and $X_2$ into the DGP makes the causal forest perform the best within all scenarios where polynomials or interactions have been considered. \n",
    "The good performance compared to Case 1 could also be explained by the fewer number of total regressors, since either one or two regressors basically include the same information as $X_1$ and/or $X_2$. The performance with fewer regressors will also be discussed in Case 6.  The one exception to the relative good performance is the inclusion of the interaction term in scenario $(2)$ with more complex treatment heterogeneity. Even with large samples the $MSE_{\\tau}$ values are particular large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9105dc6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Application</th><th scope=col>N = 100</th><th scope=col>N = 150</th><th scope=col>N = 250</th><th scope=col>N = 500</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Treatment 1</td><td>0.237      </td><td>0.187      </td><td>0.117      </td><td>0.072      </td></tr>\n",
       "\t<tr><td>Treatment 2</td><td>0.194      </td><td>0.178      </td><td>0.103      </td><td>0.072      </td></tr>\n",
       "\t<tr><td>Treatment 3</td><td>0.919      </td><td>0.742      </td><td>0.539      </td><td>0.360      </td></tr>\n",
       "\t<tr><td>Treatment 4</td><td>1.517      </td><td>1.360      </td><td>1.087      </td><td>0.783      </td></tr>\n",
       "\t<tr><td>Treatment 5</td><td>1.307      </td><td>1.208      </td><td>1.104      </td><td>0.988      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Application & N = 100 & N = 150 & N = 250 & N = 500\\\\\n",
       "\\hline\n",
       "\t Treatment 1 & 0.237       & 0.187       & 0.117       & 0.072      \\\\\n",
       "\t Treatment 2 & 0.194       & 0.178       & 0.103       & 0.072      \\\\\n",
       "\t Treatment 3 & 0.919       & 0.742       & 0.539       & 0.360      \\\\\n",
       "\t Treatment 4 & 1.517       & 1.360       & 1.087       & 0.783      \\\\\n",
       "\t Treatment 5 & 1.307       & 1.208       & 1.104       & 0.988      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Application | N = 100 | N = 150 | N = 250 | N = 500 |\n",
       "|---|---|---|---|---|\n",
       "| Treatment 1 | 0.237       | 0.187       | 0.117       | 0.072       |\n",
       "| Treatment 2 | 0.194       | 0.178       | 0.103       | 0.072       |\n",
       "| Treatment 3 | 0.919       | 0.742       | 0.539       | 0.360       |\n",
       "| Treatment 4 | 1.517       | 1.360       | 1.087       | 0.783       |\n",
       "| Treatment 5 | 1.307       | 1.208       | 1.104       | 0.988       |\n",
       "\n"
      ],
      "text/plain": [
       "  Application N = 100 N = 150 N = 250 N = 500\n",
       "1 Treatment 1 0.237   0.187   0.117   0.072  \n",
       "2 Treatment 2 0.194   0.178   0.103   0.072  \n",
       "3 Treatment 3 0.919   0.742   0.539   0.360  \n",
       "4 Treatment 4 1.517   1.360   1.087   0.783  \n",
       "5 Treatment 5 1.307   1.208   1.104   0.988  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simulation(p=10,numsim=100,regressors=\"poly1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c020d353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Application</th><th scope=col>N = 100</th><th scope=col>N = 150</th><th scope=col>N = 250</th><th scope=col>N = 500</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Treatment 1</td><td> 0.233     </td><td> 0.152     </td><td> 0.111     </td><td>0.073      </td></tr>\n",
       "\t<tr><td>Treatment 2</td><td> 0.227     </td><td> 0.150     </td><td> 0.120     </td><td>0.068      </td></tr>\n",
       "\t<tr><td>Treatment 3</td><td> 3.037     </td><td> 2.454     </td><td> 1.534     </td><td>0.850      </td></tr>\n",
       "\t<tr><td>Treatment 4</td><td> 3.614     </td><td> 3.075     </td><td> 2.305     </td><td>1.343      </td></tr>\n",
       "\t<tr><td>Treatment 5</td><td>13.124     </td><td>12.619     </td><td>10.595     </td><td>7.334      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Application & N = 100 & N = 150 & N = 250 & N = 500\\\\\n",
       "\\hline\n",
       "\t Treatment 1 &  0.233      &  0.152      &  0.111      & 0.073      \\\\\n",
       "\t Treatment 2 &  0.227      &  0.150      &  0.120      & 0.068      \\\\\n",
       "\t Treatment 3 &  3.037      &  2.454      &  1.534      & 0.850      \\\\\n",
       "\t Treatment 4 &  3.614      &  3.075      &  2.305      & 1.343      \\\\\n",
       "\t Treatment 5 & 13.124      & 12.619      & 10.595      & 7.334      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Application | N = 100 | N = 150 | N = 250 | N = 500 |\n",
       "|---|---|---|---|---|\n",
       "| Treatment 1 |  0.233      |  0.152      |  0.111      | 0.073       |\n",
       "| Treatment 2 |  0.227      |  0.150      |  0.120      | 0.068       |\n",
       "| Treatment 3 |  3.037      |  2.454      |  1.534      | 0.850       |\n",
       "| Treatment 4 |  3.614      |  3.075      |  2.305      | 1.343       |\n",
       "| Treatment 5 | 13.124      | 12.619      | 10.595      | 7.334       |\n",
       "\n"
      ],
      "text/plain": [
       "  Application N = 100 N = 150 N = 250 N = 500\n",
       "1 Treatment 1  0.233   0.152   0.111  0.073  \n",
       "2 Treatment 2  0.227   0.150   0.120  0.068  \n",
       "3 Treatment 3  3.037   2.454   1.534  0.850  \n",
       "4 Treatment 4  3.614   3.075   2.305  1.343  \n",
       "5 Treatment 5 13.124  12.619  10.595  7.334  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simulation(p=10,numsim=100,regressors=\"poly2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1db1ff61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Application</th><th scope=col>N = 100</th><th scope=col>N = 150</th><th scope=col>N = 250</th><th scope=col>N = 500</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Treatment 1</td><td>0.206      </td><td>0.157      </td><td>0.099      </td><td>0.076      </td></tr>\n",
       "\t<tr><td>Treatment 2</td><td>0.294      </td><td>0.194      </td><td>0.118      </td><td>0.073      </td></tr>\n",
       "\t<tr><td>Treatment 3</td><td>0.835      </td><td>0.683      </td><td>0.512      </td><td>0.348      </td></tr>\n",
       "\t<tr><td>Treatment 4</td><td>1.517      </td><td>1.321      </td><td>1.025      </td><td>0.750      </td></tr>\n",
       "\t<tr><td>Treatment 5</td><td>1.031      </td><td>0.926      </td><td>0.715      </td><td>0.481      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Application & N = 100 & N = 150 & N = 250 & N = 500\\\\\n",
       "\\hline\n",
       "\t Treatment 1 & 0.206       & 0.157       & 0.099       & 0.076      \\\\\n",
       "\t Treatment 2 & 0.294       & 0.194       & 0.118       & 0.073      \\\\\n",
       "\t Treatment 3 & 0.835       & 0.683       & 0.512       & 0.348      \\\\\n",
       "\t Treatment 4 & 1.517       & 1.321       & 1.025       & 0.750      \\\\\n",
       "\t Treatment 5 & 1.031       & 0.926       & 0.715       & 0.481      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Application | N = 100 | N = 150 | N = 250 | N = 500 |\n",
       "|---|---|---|---|---|\n",
       "| Treatment 1 | 0.206       | 0.157       | 0.099       | 0.076       |\n",
       "| Treatment 2 | 0.294       | 0.194       | 0.118       | 0.073       |\n",
       "| Treatment 3 | 0.835       | 0.683       | 0.512       | 0.348       |\n",
       "| Treatment 4 | 1.517       | 1.321       | 1.025       | 0.750       |\n",
       "| Treatment 5 | 1.031       | 0.926       | 0.715       | 0.481       |\n",
       "\n"
      ],
      "text/plain": [
       "  Application N = 100 N = 150 N = 250 N = 500\n",
       "1 Treatment 1 0.206   0.157   0.099   0.076  \n",
       "2 Treatment 2 0.294   0.194   0.118   0.073  \n",
       "3 Treatment 3 0.835   0.683   0.512   0.348  \n",
       "4 Treatment 4 1.517   1.321   1.025   0.750  \n",
       "5 Treatment 5 1.031   0.926   0.715   0.481  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simulation(p=10,numsim=100,regressors=\"interaction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252390b4",
   "metadata": {},
   "source": [
    "### Case 3 - Correlation between Regressors\n",
    "\n",
    "$(1) \\quad \\rho_{j,k} = 0.5 \\qquad \\forall j,k = \\{1,...,10\\} \\quad s.t. \\quad j \\ne k  $\n",
    "\n",
    "$(2) \\quad \\rho_{1,2} = 0.9$\n",
    "\n",
    "**Description & Result**\n",
    "\n",
    "Case 3 deals with correlation between regressors. In scenario $(1)$ all regressors are moderately correlated with each other with $\\rho = 0.5$ and in $(2)$ only the two regressors that influence treatment heterogeneity are highly correlated with $\\rho = 0.9$. This exploration might be interesting for observational studies where individual characteristics might impact each other and treatment effects.\n",
    "\n",
    "In both scenarios causal forests with large sample sizes produce similiar results to Case 1, even with complex treatment heterogeneity. These findings are interesting in that causal forests seem to handle the problem of correlation between regressors very well, and should therefore be considered as a valid estimation method where other methods might fail. One reason might be that causal trees are splitting by maximizing the variance of $\\hat{\\tau}$ which will be larger if the variables affecting $\\hat{\\tau}$ are either moderately $(1)$ or even strongly $(2)$ correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b07d3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Application</th><th scope=col>N = 100</th><th scope=col>N = 150</th><th scope=col>N = 250</th><th scope=col>N = 500</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Treatment 1</td><td>0.294      </td><td>0.204      </td><td>0.091      </td><td>0.060      </td></tr>\n",
       "\t<tr><td>Treatment 2</td><td>0.297      </td><td>0.160      </td><td>0.114      </td><td>0.068      </td></tr>\n",
       "\t<tr><td>Treatment 3</td><td>1.114      </td><td>0.794      </td><td>0.594      </td><td>0.367      </td></tr>\n",
       "\t<tr><td>Treatment 4</td><td>2.583      </td><td>1.866      </td><td>1.350      </td><td>0.785      </td></tr>\n",
       "\t<tr><td>Treatment 5</td><td>1.510      </td><td>1.381      </td><td>1.134      </td><td>0.898      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Application & N = 100 & N = 150 & N = 250 & N = 500\\\\\n",
       "\\hline\n",
       "\t Treatment 1 & 0.294       & 0.204       & 0.091       & 0.060      \\\\\n",
       "\t Treatment 2 & 0.297       & 0.160       & 0.114       & 0.068      \\\\\n",
       "\t Treatment 3 & 1.114       & 0.794       & 0.594       & 0.367      \\\\\n",
       "\t Treatment 4 & 2.583       & 1.866       & 1.350       & 0.785      \\\\\n",
       "\t Treatment 5 & 1.510       & 1.381       & 1.134       & 0.898      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Application | N = 100 | N = 150 | N = 250 | N = 500 |\n",
       "|---|---|---|---|---|\n",
       "| Treatment 1 | 0.294       | 0.204       | 0.091       | 0.060       |\n",
       "| Treatment 2 | 0.297       | 0.160       | 0.114       | 0.068       |\n",
       "| Treatment 3 | 1.114       | 0.794       | 0.594       | 0.367       |\n",
       "| Treatment 4 | 2.583       | 1.866       | 1.350       | 0.785       |\n",
       "| Treatment 5 | 1.510       | 1.381       | 1.134       | 0.898       |\n",
       "\n"
      ],
      "text/plain": [
       "  Application N = 100 N = 150 N = 250 N = 500\n",
       "1 Treatment 1 0.294   0.204   0.091   0.060  \n",
       "2 Treatment 2 0.297   0.160   0.114   0.068  \n",
       "3 Treatment 3 1.114   0.794   0.594   0.367  \n",
       "4 Treatment 4 2.583   1.866   1.350   0.785  \n",
       "5 Treatment 5 1.510   1.381   1.134   0.898  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simulation(p=10,numsim=100,regressors=\"corr1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf9db01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Application</th><th scope=col>N = 100</th><th scope=col>N = 150</th><th scope=col>N = 250</th><th scope=col>N = 500</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Treatment 1</td><td>0.238      </td><td>0.128      </td><td>0.105      </td><td>0.065      </td></tr>\n",
       "\t<tr><td>Treatment 2</td><td>0.231      </td><td>0.148      </td><td>0.112      </td><td>0.079      </td></tr>\n",
       "\t<tr><td>Treatment 3</td><td>1.179      </td><td>0.928      </td><td>0.594      </td><td>0.305      </td></tr>\n",
       "\t<tr><td>Treatment 4</td><td>1.947      </td><td>1.525      </td><td>1.136      </td><td>0.709      </td></tr>\n",
       "\t<tr><td>Treatment 5</td><td>1.935      </td><td>1.960      </td><td>1.552      </td><td>0.960      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Application & N = 100 & N = 150 & N = 250 & N = 500\\\\\n",
       "\\hline\n",
       "\t Treatment 1 & 0.238       & 0.128       & 0.105       & 0.065      \\\\\n",
       "\t Treatment 2 & 0.231       & 0.148       & 0.112       & 0.079      \\\\\n",
       "\t Treatment 3 & 1.179       & 0.928       & 0.594       & 0.305      \\\\\n",
       "\t Treatment 4 & 1.947       & 1.525       & 1.136       & 0.709      \\\\\n",
       "\t Treatment 5 & 1.935       & 1.960       & 1.552       & 0.960      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Application | N = 100 | N = 150 | N = 250 | N = 500 |\n",
       "|---|---|---|---|---|\n",
       "| Treatment 1 | 0.238       | 0.128       | 0.105       | 0.065       |\n",
       "| Treatment 2 | 0.231       | 0.148       | 0.112       | 0.079       |\n",
       "| Treatment 3 | 1.179       | 0.928       | 0.594       | 0.305       |\n",
       "| Treatment 4 | 1.947       | 1.525       | 1.136       | 0.709       |\n",
       "| Treatment 5 | 1.935       | 1.960       | 1.552       | 0.960       |\n",
       "\n"
      ],
      "text/plain": [
       "  Application N = 100 N = 150 N = 250 N = 500\n",
       "1 Treatment 1 0.238   0.128   0.105   0.065  \n",
       "2 Treatment 2 0.231   0.148   0.112   0.079  \n",
       "3 Treatment 3 1.179   0.928   0.594   0.305  \n",
       "4 Treatment 4 1.947   1.525   1.136   0.709  \n",
       "5 Treatment 5 1.935   1.960   1.552   0.960  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simulation(p=10,numsim=100,regressors=\"corr2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0c9504",
   "metadata": {},
   "source": [
    "### Case 4 - Treatment variables don't influence Y\n",
    "\n",
    "$(1) \\quad \\beta_1, \\beta_2 = 0$\n",
    "\n",
    "**Description & Result**\n",
    "\n",
    "In Case 4 both $X_1$ and $X_2$ influence treatment effect heterogeneity, but don't have any influence on the output variable $Y$. Since the number of regressors has an impact of how well the estimation method performs, I conduct this analysis with 12 regressors (minus the two regressors with $\\beta = 0$) in order to assure comparability to Case 1 with 10 regressors in total. \n",
    "\n",
    "Causal forests perform very similiar to the scenario where $\\beta_1, \\beta_2 \\neq 0$, indicating that they are able to detect heterogeneity based on variables that don't influence $Y$. This makes sense from a theoretical point of view, since the splits of the tree are being made as to generate some high level of treatment variation between the split directions. Therefore, detection of treatment heterogeneity works as long as these variables are included in the dataset, eventhough they don't influence $Y$ directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22ec76e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Application</th><th scope=col>N = 100</th><th scope=col>N = 150</th><th scope=col>N = 250</th><th scope=col>N = 500</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Treatment 1</td><td>0.151      </td><td>0.138      </td><td>0.104      </td><td>0.062      </td></tr>\n",
       "\t<tr><td>Treatment 2</td><td>0.188      </td><td>0.149      </td><td>0.090      </td><td>0.057      </td></tr>\n",
       "\t<tr><td>Treatment 3</td><td>0.798      </td><td>0.685      </td><td>0.530      </td><td>0.352      </td></tr>\n",
       "\t<tr><td>Treatment 4</td><td>1.418      </td><td>1.305      </td><td>1.026      </td><td>0.738      </td></tr>\n",
       "\t<tr><td>Treatment 5</td><td>1.220      </td><td>1.132      </td><td>1.088      </td><td>0.981      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Application & N = 100 & N = 150 & N = 250 & N = 500\\\\\n",
       "\\hline\n",
       "\t Treatment 1 & 0.151       & 0.138       & 0.104       & 0.062      \\\\\n",
       "\t Treatment 2 & 0.188       & 0.149       & 0.090       & 0.057      \\\\\n",
       "\t Treatment 3 & 0.798       & 0.685       & 0.530       & 0.352      \\\\\n",
       "\t Treatment 4 & 1.418       & 1.305       & 1.026       & 0.738      \\\\\n",
       "\t Treatment 5 & 1.220       & 1.132       & 1.088       & 0.981      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Application | N = 100 | N = 150 | N = 250 | N = 500 |\n",
       "|---|---|---|---|---|\n",
       "| Treatment 1 | 0.151       | 0.138       | 0.104       | 0.062       |\n",
       "| Treatment 2 | 0.188       | 0.149       | 0.090       | 0.057       |\n",
       "| Treatment 3 | 0.798       | 0.685       | 0.530       | 0.352       |\n",
       "| Treatment 4 | 1.418       | 1.305       | 1.026       | 0.738       |\n",
       "| Treatment 5 | 1.220       | 1.132       | 1.088       | 0.981       |\n",
       "\n"
      ],
      "text/plain": [
       "  Application N = 100 N = 150 N = 250 N = 500\n",
       "1 Treatment 1 0.151   0.138   0.104   0.062  \n",
       "2 Treatment 2 0.188   0.149   0.090   0.057  \n",
       "3 Treatment 3 0.798   0.685   0.530   0.352  \n",
       "4 Treatment 4 1.418   1.305   1.026   0.738  \n",
       "5 Treatment 5 1.220   1.132   1.088   0.981  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simulation(p=10,numsim=100,regressors=\"beta12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5be37d6",
   "metadata": {},
   "source": [
    "### Case 5 - Treatment Probability depends on $X$\n",
    "\n",
    "$(1) \\quad Prob(W_i = 1 \\mid x_1>0) = 0.75 \\quad $ and $\\quad Prob(W_i = 1 \\mid x_1<0) = 0.25 $\n",
    "\n",
    "**Description & Result**\n",
    "\n",
    "Before marginal treatment probability has been fixed at 0.5 for all individuals. In this scenario selection bias will be introduced. Those individuals profiting more from treatment, i.e. individuals with positive values in the $X_1$ characteristic, are more likely to be assigned to treatment. Treatment probability for $X_1 > 0$ is 0.75, whereas treatment probability for $X_1 < 0$ is only 0.25. The analysis of this case has importance in observational studies where randomization in treatment assignment can often not be assured.  \n",
    "\n",
    "We see a slight increase in $MSE_{\\tau}$ compared to Case 1 for 100 and 150 observations, but causal forests perform relatively worse for 500 observations, indicating that the performance with selection bias cannot quite keep up in large scale samples, where this method usually has its largest improvements, as seen in previous cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8ff4322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Application</th><th scope=col>N = 100</th><th scope=col>N = 150</th><th scope=col>N = 250</th><th scope=col>N = 500</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Treatment 1</td><td>0.297      </td><td>0.335      </td><td>0.235      </td><td>0.224      </td></tr>\n",
       "\t<tr><td>Treatment 2</td><td>0.352      </td><td>0.317      </td><td>0.275      </td><td>0.228      </td></tr>\n",
       "\t<tr><td>Treatment 3</td><td>1.204      </td><td>1.077      </td><td>0.879      </td><td>0.485      </td></tr>\n",
       "\t<tr><td>Treatment 4</td><td>1.919      </td><td>1.686      </td><td>1.442      </td><td>0.925      </td></tr>\n",
       "\t<tr><td>Treatment 5</td><td>1.325      </td><td>1.345      </td><td>1.310      </td><td>1.201      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Application & N = 100 & N = 150 & N = 250 & N = 500\\\\\n",
       "\\hline\n",
       "\t Treatment 1 & 0.297       & 0.335       & 0.235       & 0.224      \\\\\n",
       "\t Treatment 2 & 0.352       & 0.317       & 0.275       & 0.228      \\\\\n",
       "\t Treatment 3 & 1.204       & 1.077       & 0.879       & 0.485      \\\\\n",
       "\t Treatment 4 & 1.919       & 1.686       & 1.442       & 0.925      \\\\\n",
       "\t Treatment 5 & 1.325       & 1.345       & 1.310       & 1.201      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Application | N = 100 | N = 150 | N = 250 | N = 500 |\n",
       "|---|---|---|---|---|\n",
       "| Treatment 1 | 0.297       | 0.335       | 0.235       | 0.224       |\n",
       "| Treatment 2 | 0.352       | 0.317       | 0.275       | 0.228       |\n",
       "| Treatment 3 | 1.204       | 1.077       | 0.879       | 0.485       |\n",
       "| Treatment 4 | 1.919       | 1.686       | 1.442       | 0.925       |\n",
       "| Treatment 5 | 1.325       | 1.345       | 1.310       | 1.201       |\n",
       "\n"
      ],
      "text/plain": [
       "  Application N = 100 N = 150 N = 250 N = 500\n",
       "1 Treatment 1 0.297   0.335   0.235   0.224  \n",
       "2 Treatment 2 0.352   0.317   0.275   0.228  \n",
       "3 Treatment 3 1.204   1.077   0.879   0.485  \n",
       "4 Treatment 4 1.919   1.686   1.442   0.925  \n",
       "5 Treatment 5 1.325   1.345   1.310   1.201  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simulation(p=10,numsim=100,regressors=\"selectionbias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f902ac2a",
   "metadata": {},
   "source": [
    "### Case 6 - Number of Regressors\n",
    "\n",
    "$(1) \\quad p \\in \\{4,20,50,100\\}$\n",
    "\n",
    "**Description & Result**\n",
    "\n",
    "In Case 6 performance with a different number of regressors is compared where the number of regressors is varied between 4 and 100. This comparison might be interesting in applications where the researcher has a data set containing a lot of different characteristics. \n",
    "\n",
    "I find that the overall performance decreases if more regressors are added, whereas causal forest signficantly decreases $MSE_{\\tau}$ going from 100 to 500 observations. So, even if one has a high dimensional data set, this simulation study shows that if the number of observations is large enough the causal forest will perform quite well. The relatively good performance in high dimensional space can be explained theoretically by it's variable selection feature. By training the trees with only the most \"important\" variables, only a couple of them will be selected by the causal tree overall. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cf6b729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Application</th><th scope=col>N = 100</th><th scope=col>N = 150</th><th scope=col>N = 250</th><th scope=col>N = 500</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Treatment 1</td><td>0.090      </td><td>0.061      </td><td>0.048      </td><td>0.034      </td></tr>\n",
       "\t<tr><td>Treatment 2</td><td>0.081      </td><td>0.071      </td><td>0.058      </td><td>0.039      </td></tr>\n",
       "\t<tr><td>Treatment 3</td><td>0.614      </td><td>0.484      </td><td>0.308      </td><td>0.189      </td></tr>\n",
       "\t<tr><td>Treatment 4</td><td>1.310      </td><td>1.096      </td><td>0.930      </td><td>0.844      </td></tr>\n",
       "\t<tr><td>Treatment 5</td><td>1.051      </td><td>1.142      </td><td>0.960      </td><td>0.615      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Application & N = 100 & N = 150 & N = 250 & N = 500\\\\\n",
       "\\hline\n",
       "\t Treatment 1 & 0.090       & 0.061       & 0.048       & 0.034      \\\\\n",
       "\t Treatment 2 & 0.081       & 0.071       & 0.058       & 0.039      \\\\\n",
       "\t Treatment 3 & 0.614       & 0.484       & 0.308       & 0.189      \\\\\n",
       "\t Treatment 4 & 1.310       & 1.096       & 0.930       & 0.844      \\\\\n",
       "\t Treatment 5 & 1.051       & 1.142       & 0.960       & 0.615      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Application | N = 100 | N = 150 | N = 250 | N = 500 |\n",
       "|---|---|---|---|---|\n",
       "| Treatment 1 | 0.090       | 0.061       | 0.048       | 0.034       |\n",
       "| Treatment 2 | 0.081       | 0.071       | 0.058       | 0.039       |\n",
       "| Treatment 3 | 0.614       | 0.484       | 0.308       | 0.189       |\n",
       "| Treatment 4 | 1.310       | 1.096       | 0.930       | 0.844       |\n",
       "| Treatment 5 | 1.051       | 1.142       | 0.960       | 0.615       |\n",
       "\n"
      ],
      "text/plain": [
       "  Application N = 100 N = 150 N = 250 N = 500\n",
       "1 Treatment 1 0.090   0.061   0.048   0.034  \n",
       "2 Treatment 2 0.081   0.071   0.058   0.039  \n",
       "3 Treatment 3 0.614   0.484   0.308   0.189  \n",
       "4 Treatment 4 1.310   1.096   0.930   0.844  \n",
       "5 Treatment 5 1.051   1.142   0.960   0.615  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simulation(p=4,numsim=100,regressors=\"nocorr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b20ba5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Application</th><th scope=col>N = 100</th><th scope=col>N = 150</th><th scope=col>N = 250</th><th scope=col>N = 500</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Treatment 1</td><td>0.446      </td><td>0.289      </td><td>0.216      </td><td>0.153      </td></tr>\n",
       "\t<tr><td>Treatment 2</td><td>0.456      </td><td>0.318      </td><td>0.193      </td><td>0.133      </td></tr>\n",
       "\t<tr><td>Treatment 3</td><td>1.057      </td><td>0.970      </td><td>0.748      </td><td>0.583      </td></tr>\n",
       "\t<tr><td>Treatment 4</td><td>1.786      </td><td>1.583      </td><td>1.372      </td><td>1.084      </td></tr>\n",
       "\t<tr><td>Treatment 5</td><td>1.355      </td><td>1.411      </td><td>1.235      </td><td>1.132      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Application & N = 100 & N = 150 & N = 250 & N = 500\\\\\n",
       "\\hline\n",
       "\t Treatment 1 & 0.446       & 0.289       & 0.216       & 0.153      \\\\\n",
       "\t Treatment 2 & 0.456       & 0.318       & 0.193       & 0.133      \\\\\n",
       "\t Treatment 3 & 1.057       & 0.970       & 0.748       & 0.583      \\\\\n",
       "\t Treatment 4 & 1.786       & 1.583       & 1.372       & 1.084      \\\\\n",
       "\t Treatment 5 & 1.355       & 1.411       & 1.235       & 1.132      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Application | N = 100 | N = 150 | N = 250 | N = 500 |\n",
       "|---|---|---|---|---|\n",
       "| Treatment 1 | 0.446       | 0.289       | 0.216       | 0.153       |\n",
       "| Treatment 2 | 0.456       | 0.318       | 0.193       | 0.133       |\n",
       "| Treatment 3 | 1.057       | 0.970       | 0.748       | 0.583       |\n",
       "| Treatment 4 | 1.786       | 1.583       | 1.372       | 1.084       |\n",
       "| Treatment 5 | 1.355       | 1.411       | 1.235       | 1.132       |\n",
       "\n"
      ],
      "text/plain": [
       "  Application N = 100 N = 150 N = 250 N = 500\n",
       "1 Treatment 1 0.446   0.289   0.216   0.153  \n",
       "2 Treatment 2 0.456   0.318   0.193   0.133  \n",
       "3 Treatment 3 1.057   0.970   0.748   0.583  \n",
       "4 Treatment 4 1.786   1.583   1.372   1.084  \n",
       "5 Treatment 5 1.355   1.411   1.235   1.132  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simulation(p=20,numsim=100,regressors=\"nocorr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1689117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Application</th><th scope=col>N = 100</th><th scope=col>N = 150</th><th scope=col>N = 250</th><th scope=col>N = 500</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Treatment 1</td><td>1.305      </td><td>0.656      </td><td>0.444      </td><td>0.259      </td></tr>\n",
       "\t<tr><td>Treatment 2</td><td>1.152      </td><td>1.047      </td><td>0.461      </td><td>0.267      </td></tr>\n",
       "\t<tr><td>Treatment 3</td><td>2.095      </td><td>1.633      </td><td>1.127      </td><td>0.944      </td></tr>\n",
       "\t<tr><td>Treatment 4</td><td>2.637      </td><td>2.124      </td><td>1.759      </td><td>1.536      </td></tr>\n",
       "\t<tr><td>Treatment 5</td><td>2.581      </td><td>1.638      </td><td>1.383      </td><td>1.244      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Application & N = 100 & N = 150 & N = 250 & N = 500\\\\\n",
       "\\hline\n",
       "\t Treatment 1 & 1.305       & 0.656       & 0.444       & 0.259      \\\\\n",
       "\t Treatment 2 & 1.152       & 1.047       & 0.461       & 0.267      \\\\\n",
       "\t Treatment 3 & 2.095       & 1.633       & 1.127       & 0.944      \\\\\n",
       "\t Treatment 4 & 2.637       & 2.124       & 1.759       & 1.536      \\\\\n",
       "\t Treatment 5 & 2.581       & 1.638       & 1.383       & 1.244      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Application | N = 100 | N = 150 | N = 250 | N = 500 |\n",
       "|---|---|---|---|---|\n",
       "| Treatment 1 | 1.305       | 0.656       | 0.444       | 0.259       |\n",
       "| Treatment 2 | 1.152       | 1.047       | 0.461       | 0.267       |\n",
       "| Treatment 3 | 2.095       | 1.633       | 1.127       | 0.944       |\n",
       "| Treatment 4 | 2.637       | 2.124       | 1.759       | 1.536       |\n",
       "| Treatment 5 | 2.581       | 1.638       | 1.383       | 1.244       |\n",
       "\n"
      ],
      "text/plain": [
       "  Application N = 100 N = 150 N = 250 N = 500\n",
       "1 Treatment 1 1.305   0.656   0.444   0.259  \n",
       "2 Treatment 2 1.152   1.047   0.461   0.267  \n",
       "3 Treatment 3 2.095   1.633   1.127   0.944  \n",
       "4 Treatment 4 2.637   2.124   1.759   1.536  \n",
       "5 Treatment 5 2.581   1.638   1.383   1.244  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simulation(p=50,numsim=100,regressors=\"nocorr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f3b05d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Application</th><th scope=col>N = 100</th><th scope=col>N = 150</th><th scope=col>N = 250</th><th scope=col>N = 500</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Treatment 1</td><td>2.487      </td><td>1.668      </td><td>1.064      </td><td>0.573      </td></tr>\n",
       "\t<tr><td>Treatment 2</td><td>2.327      </td><td>1.665      </td><td>0.903      </td><td>0.436      </td></tr>\n",
       "\t<tr><td>Treatment 3</td><td>3.419      </td><td>2.258      </td><td>1.605      </td><td>1.133      </td></tr>\n",
       "\t<tr><td>Treatment 4</td><td>4.198      </td><td>2.867      </td><td>2.192      </td><td>1.895      </td></tr>\n",
       "\t<tr><td>Treatment 5</td><td>4.019      </td><td>2.636      </td><td>1.874      </td><td>1.481      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Application & N = 100 & N = 150 & N = 250 & N = 500\\\\\n",
       "\\hline\n",
       "\t Treatment 1 & 2.487       & 1.668       & 1.064       & 0.573      \\\\\n",
       "\t Treatment 2 & 2.327       & 1.665       & 0.903       & 0.436      \\\\\n",
       "\t Treatment 3 & 3.419       & 2.258       & 1.605       & 1.133      \\\\\n",
       "\t Treatment 4 & 4.198       & 2.867       & 2.192       & 1.895      \\\\\n",
       "\t Treatment 5 & 4.019       & 2.636       & 1.874       & 1.481      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Application | N = 100 | N = 150 | N = 250 | N = 500 |\n",
       "|---|---|---|---|---|\n",
       "| Treatment 1 | 2.487       | 1.668       | 1.064       | 0.573       |\n",
       "| Treatment 2 | 2.327       | 1.665       | 0.903       | 0.436       |\n",
       "| Treatment 3 | 3.419       | 2.258       | 1.605       | 1.133       |\n",
       "| Treatment 4 | 4.198       | 2.867       | 2.192       | 1.895       |\n",
       "| Treatment 5 | 4.019       | 2.636       | 1.874       | 1.481       |\n",
       "\n"
      ],
      "text/plain": [
       "  Application N = 100 N = 150 N = 250 N = 500\n",
       "1 Treatment 1 2.487   1.668   1.064   0.573  \n",
       "2 Treatment 2 2.327   1.665   0.903   0.436  \n",
       "3 Treatment 3 3.419   2.258   1.605   1.133  \n",
       "4 Treatment 4 4.198   2.867   2.192   1.895  \n",
       "5 Treatment 5 4.019   2.636   1.874   1.481  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simulation(p=100,numsim=100,regressors=\"nocorr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cc94b7",
   "metadata": {},
   "source": [
    "# 3.) Application<a id=\"application\"></a>\n",
    "\n",
    "## Lalonde Data Set<a id=\"lalonde\"></a>\n",
    "\n",
    "The estimation of treatment effects has always been a prominent and important topic especially in the area of labor economics. I hereby refer to the discussions of the Lalonde (1986) and Dehejia & Wahba (1998) papers, which have been described in Cunningham (2021). To be in line with the topic of this final project, I reconsider the Lalonde data set, which can be downloaded [here](https://users.nber.org/~rdehejia/nswdata.html), and apply the causal forest estimation method in order to check for heterogeneity in treatment effects.\n",
    "\n",
    "Both papers deal with the effectiveness of the NSW program which \"was a temporary employment program designed to help disadvantaged workers lacking basic job skills move into the labor market\" where applicants were assigned \"to training positions randomly\" (LaLonde 1986). However, they only distinguish between female and male treatment effects. That's why I wanted to extent this analysis by evaluating the heterogeneity in treatment effects in greater detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78625b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>data_id</th><th scope=col>treat</th><th scope=col>age</th><th scope=col>education</th><th scope=col>black</th><th scope=col>hispanic</th><th scope=col>married</th><th scope=col>nodegree</th><th scope=col>re75</th><th scope=col>re78</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Lalonde Sample</td><td>1             </td><td>37            </td><td>11            </td><td>1             </td><td>0             </td><td>1             </td><td>1             </td><td>0             </td><td> 9930.0459    </td></tr>\n",
       "\t<tr><td>Lalonde Sample</td><td>1             </td><td>22            </td><td> 9            </td><td>0             </td><td>1             </td><td>0             </td><td>1             </td><td>0             </td><td> 3595.8940    </td></tr>\n",
       "\t<tr><td>Lalonde Sample</td><td>1             </td><td>30            </td><td>12            </td><td>1             </td><td>0             </td><td>0             </td><td>0             </td><td>0             </td><td>24909.4492    </td></tr>\n",
       "\t<tr><td>Lalonde Sample</td><td>1             </td><td>27            </td><td>11            </td><td>1             </td><td>0             </td><td>0             </td><td>1             </td><td>0             </td><td> 7506.1460    </td></tr>\n",
       "\t<tr><td>Lalonde Sample</td><td>1             </td><td>33            </td><td> 8            </td><td>1             </td><td>0             </td><td>0             </td><td>1             </td><td>0             </td><td>  289.7899    </td></tr>\n",
       "\t<tr><td>Lalonde Sample</td><td>1             </td><td>22            </td><td> 9            </td><td>1             </td><td>0             </td><td>0             </td><td>1             </td><td>0             </td><td> 4056.4939    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       " data\\_id & treat & age & education & black & hispanic & married & nodegree & re75 & re78\\\\\n",
       "\\hline\n",
       "\t Lalonde Sample & 1              & 37             & 11             & 1              & 0              & 1              & 1              & 0              &  9930.0459    \\\\\n",
       "\t Lalonde Sample & 1              & 22             &  9             & 0              & 1              & 0              & 1              & 0              &  3595.8940    \\\\\n",
       "\t Lalonde Sample & 1              & 30             & 12             & 1              & 0              & 0              & 0              & 0              & 24909.4492    \\\\\n",
       "\t Lalonde Sample & 1              & 27             & 11             & 1              & 0              & 0              & 1              & 0              &  7506.1460    \\\\\n",
       "\t Lalonde Sample & 1              & 33             &  8             & 1              & 0              & 0              & 1              & 0              &   289.7899    \\\\\n",
       "\t Lalonde Sample & 1              & 22             &  9             & 1              & 0              & 0              & 1              & 0              &  4056.4939    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| data_id | treat | age | education | black | hispanic | married | nodegree | re75 | re78 |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| Lalonde Sample | 1              | 37             | 11             | 1              | 0              | 1              | 1              | 0              |  9930.0459     |\n",
       "| Lalonde Sample | 1              | 22             |  9             | 0              | 1              | 0              | 1              | 0              |  3595.8940     |\n",
       "| Lalonde Sample | 1              | 30             | 12             | 1              | 0              | 0              | 0              | 0              | 24909.4492     |\n",
       "| Lalonde Sample | 1              | 27             | 11             | 1              | 0              | 0              | 1              | 0              |  7506.1460     |\n",
       "| Lalonde Sample | 1              | 33             |  8             | 1              | 0              | 0              | 1              | 0              |   289.7899     |\n",
       "| Lalonde Sample | 1              | 22             |  9             | 1              | 0              | 0              | 1              | 0              |  4056.4939     |\n",
       "\n"
      ],
      "text/plain": [
       "  data_id        treat age education black hispanic married nodegree re75\n",
       "1 Lalonde Sample 1     37  11        1     0        1       1        0   \n",
       "2 Lalonde Sample 1     22   9        0     1        0       1        0   \n",
       "3 Lalonde Sample 1     30  12        1     0        0       0        0   \n",
       "4 Lalonde Sample 1     27  11        1     0        0       1        0   \n",
       "5 Lalonde Sample 1     33   8        1     0        0       1        0   \n",
       "6 Lalonde Sample 1     22   9        1     0        0       1        0   \n",
       "  re78      \n",
       "1  9930.0459\n",
       "2  3595.8940\n",
       "3 24909.4492\n",
       "4  7506.1460\n",
       "5   289.7899\n",
       "6  4056.4939"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_nsw <- read.dta(\"material/nsw.dta\")\n",
    "head(data_nsw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14dc737",
   "metadata": {},
   "source": [
    "## Causal Forest Estimations<a id=\"causalforest\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5972d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "887b318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y <- data_nsw$re78\n",
    "W <- data_nsw$treat\n",
    "X <- data_nsw[,-c(1,2,10)]\n",
    "\n",
    "#### Untrainted CF\n",
    "cf_nsw_pilot <- causal_forest(X, Y, W , num.trees = 10000)\n",
    "var_imp <- variable_importance(cf_nsw_pilot) \n",
    "select_index <- which(var_imp >= mean(var_imp))\n",
    "\n",
    "#### Trained CF\n",
    "cf_nsw <- causal_forest(X[, select_index], Y, W,num.trees = 10000)\n",
    "tau_hat <- predict(cf_nsw)$predictions\n",
    "data_nsw[\"t_hat\"] = tau_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdd28a8",
   "metadata": {},
   "source": [
    "### Average Treatment Effect\n",
    "\n",
    "The Average Treatment Effect estimated by the causal forest, now using $B =10000$ causal trees per forest, is 819.4 \\\\$. Therefore, participants of the jobmarket training program earn on average 819.4 \\\\$ more than people in the control group.\n",
    "This estimate is close to the results in Lalonde (1986) where the treatment effects are around 890 \\\\$ (Table 6), depending on the control group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dc250b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>estimate</dt>\n",
       "\t\t<dd>819.355868022342</dd>\n",
       "\t<dt>std.err</dt>\n",
       "\t\t<dd>490.374654904794</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[estimate] 819.355868022342\n",
       "\\item[std.err] 490.374654904794\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "estimate\n",
       ":   819.355868022342std.err\n",
       ":   490.374654904794\n",
       "\n"
      ],
      "text/plain": [
       "estimate  std.err \n",
       "819.3559 490.3747 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Average Treatment Effect\n",
    "\n",
    "average_treatment_effect(cf_nsw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df909743",
   "metadata": {},
   "source": [
    "### Check for Heterogeneity (1)\n",
    "\n",
    "The analysis of treatment effect heterogeneity in observational data follows the Athey & Wager (2019) paper.\n",
    "A first check for heterogeneity involves the frequencies of the estimated Conditional Average Treatment Effects. The Histogram below shows that there's a very wide span of CATEs, ranging from -1000 \\\\$ to +3000 \\\\$, indicating that treatment effects might differ across individuals or some covariates. But this first glance can be flawed and Athey et al. (2020) warn, that \"if the histogram is spread out, it may be that the forests are simply overfitting and producing very noisy estimates\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ceeea064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM\njIyampqnp6eysrK9vb3Hx8fQ0NDZ2dnh4eHp6enw8PD////QFLu4AAAACXBIWXMAABJ0AAAS\ndAHeZh94AAAgAElEQVR4nO3d64KaOhRAYfBeL/j+b1tFUUDCBNwJe2/X9+PUaScEE1adUU+n\nuAL4WrH0CQAeEBIggJAAAYQECCAkQAAhAQIICRBASIAAQgIEEBIggJAAAYQECCAkQAAhAQII\nCRBASIAAQgIEEBIggJAAAYQECCAkQAAhAQIICRBASIAAQgIEEBIggJAAAYQECCAkQAAhAQII\nCRBASIAAQgIEEBIggJAAAYQECCAkQAAhAQIICRBASIAAQgIEuAipKIrurfdvtG2znMy+LIrO\nTKftqijKzb8pB+nfj+218+HU47w+eIs9wuxF6wz8mLpZpY/VEjyDrH4npFOZ5b7u75dKe+83\nzfVTnuKP0r0fzannD2n2ovUG9qduVuljteTOIDMbZ/mHqJCmX4Wz3B59zu2P160r6Bwa9KF7\nP5pTzx/S7EXrDexP3axSf7UEzyAzG2f5h4+Qxj8p07nUbo9H5aG6Xi+H2x9sZh5l/ql/jpx2\nLMGQBv/47+MTUkahR6Rqf388qL87af89fNzev544Podcbh+tD62Rl1Wxu936d/+abLW7NMc7\nrIrV7YuzQ1mse1+jdY7X3fjzraPL8+Zqfxn+9OPtLLfn5mzKYnXo3I/3qb+OPXqI/omH1qp1\nX6tdWZS7S398d+bPBWgP65zFx6PenyF1zqDa3R6p1sfOgVp7qZLnkC7lcx/Wna1tvth6PD6c\nnp/yHrmqB7y+JDs9fvfx8WX3+r2X9vH6V9Dt0w+9k+1Of7vxOOTjS5zPsxkKafQQ/RMPrtX7\nvjYLdeqN78z8uQCdYZ2z6C/D5yNs/cfvT+scqvlg1zpQey9V8hzS7a/t219g1fp+Mb/37PXN\n/+M6LF8fNiOL+7DbV2Lrqg6h1cft4aV9BT90jte/gm5zX7rn2pv+Pft2+GwGQho9xMeJB9fq\ndV9fs5a98Z2ZPxegPax7Fv1l+DOkzqFei3B8f0Z7L1XyEtLABVh/6XL7pbr9xfv6vevx9uvt\nm5ZqX2/U9d9t8+6/lO+R9+vo/l3wpXOk2+/ev81Znetf3nP3jvfXdzcDn36ff/v4xOfZHMvO\n/eh9ITR+iI8T/1yr1s36vj7aqR7X6vD4oQXoDOudxdiTDZ/3qHuo2wfluW6mtW3dvVTIc0j3\ny/H1rVCzI9vm77Rd/Xfn5nEx3i/hZuSxd+jHf0+dX96f0DveXyENfPp9vqpoHi3r2Y9jIY0f\n4uPEP9eqdbOe7TZr9fh4Exo/tADdYb2zmBZS51DPRage31M+P6O7lwp5Dmn/+I3n+r//qN6z\n66X+jbLZ8P4f3z7h325ddK6noYukd7y/Qgp9em/wWEjjhxg88eEzKl6Xb6MMjR86n+6w4c9s\nTTUWUudQgyvY3UuFvITUvfX8ZdfszuXjj5pbgUv39hC1am38eEidW93L4ON1ktCnTwtp5BCD\nJz54Au2BrSGD48dDCn/mwKz9qT/OYDCk7l4q5Dqka/Xv8VzTuvNHr7/Py8FHpPrD+5d6q+3h\nHBNS+3i9y+DjWbvQp08LaeQQgyc+uFavm2X7k4bHD51PZ9h3IZW9FR0a2d5LhXyHdHfcdq6J\nzZ/fI9V/unr+/p8hbUa/Rzq9/wo91V/zhz798WvgbD4+aeQQgyc+uFavm5v294XD44fOpzPs\nu5A6h1oPfY/00OylQkpPa5pASKvX9wDNX9xV8Fm7YvCavf79iDT+rN37nQ33P9+EP/3x6+Hz\nOcTml+r14fghBk98cK3aj7739wH+a15w641/z9z9pTNsKKRqcNbOx89fO4f6fNau6u+lQp5D\nul1x60v9fer91fv7xXn/9f3mt+ArN4/P2r2fhx4JqX+83iVTtY5fPzYFPr14fY0zcDbNqT8/\nHD3E4IkPrtX75mvWU398b+bP02qGDd2RXWfWzj3rfXb3UK8PDu8DdfdSIc8hvb5Brb+s3jY3\nmuvw8abj4/NTepGcmou/3tuxkHrH61+61euyX11GPv3563PaTXem5tSbTx47xOCJD67V++Zz\nDeprtDu+N3P3l/aw/h15rfZrqtGQOoc6la0PmgN19lIh1yE9vqZeP7/d37za2ZatJ1LP2/p9\nXf1I7r9dbs+X5g0LA0dvdI73eenWf7x6P3E7+OnNrx/v/Guf+vvKHznE0IkPrlXrZv3mts3x\n8473Zu6dVntY/468Vrv53dGQOoeq33j3+qA5UGcv9XERkoBK7RffMOHXQyoeb3A5r6f8Tw5A\n36+H1Pr/7tS+aA4Dfj2k19vztT4bBBt+PaRrtb8/RVbqfRMXTPj5kAAJhAQIICRAACEBAggJ\nEEBIgABCAgQQEiCAkAABhAQIICRAACEBAggJEEBIgABCAgQQEiCAkAABhAQIICRAACEBAggJ\nEEBIgABCAgQQEiCAkAABhAQIICRAACEBAggJEEBIgABCAgQQEiCAkAABhAQIICRAACEBAggJ\nEEBIgABCAgQQEiCAkAABhAQIICRAACEBAggJEEBIgABCAgQQEiCAkAABhAQIICRAACEBAggJ\nEEBIgABCAgQQEiCAkAABhKRa8YWlz/23sNyqfbE97GxWLLdqhGQFy60aIVnBcqtGSFaw3KoR\nkhUst2qEZAXLrRohWcFyq0ZIVrDcqhGSFSy3aoRkBcutGiFZwXKrRkhWsNyqEZIVLLdqhGQF\ny60aIVnBcqtGSFaw3KoRkhUst2qEZAXLrRohWcFyq0ZIVrDcqhGSFSy3aoRkBcutGiFZwXKr\nRkhWsNyqEZIVLLdqhGQFy60aIVnBcqtGSFaw3KoRkhUst2qEZAXLrRohWcFyq0ZIVrDcqhGS\nFSy3aoRkBcutGiFZwXKrRkhWsNyqEZIVLLdqhGQFy60aIVnBcqtGSFaw3KoRkhUst2qEZAXL\nrRohWcFyq0ZIVrDcqhGSFSy3aoRkBcutGiFZwXKrRkhWsNyqEZIVLLdqhGQFy60aIVnBcqtG\nSFaw3KoRkhUst2qEZAXLrRohWcFyq0ZIVrDcqhGSFSy3aoRkBcutGiFZwXKrRkhWsNyqEZIV\nLLdqhGQFy60aIVnBcqtGSFaw3KoRkhUst2qEZAXLrRohWcFyq0ZIVrDcqhGSFSy3aoRkBcut\nGiFZMX+5T/tNcbfZnQTPBx2EZMXc5a5Wxdta9JTwRkhWzF3uXVH+O9e3Lsey2MmdENoIyYq5\ny10W59ftc1HKnAz6CMmKuctdFKEPIIiQrOARSTVCsuKL75GOl/oW3yMlREhWzF7udetZu1Ul\neUp4IyQrvngdaVe/jlRu9ryOlAwhWcFyq0ZIVrDcqhGSFV8u92FVFJujzKngEyFZ8d3rSM9n\nHHjSLhVCsuKrkHbFrrpeL7viIHlKeCMkK74KqSzq572rYiV3QmgjJCu+Cql5a9DnW4SKtvln\n9/MIyYqvQto2IY2+RYgdnY+QrJgf0mZ/OBb/bjer3fizDezofIRkxfyQXl+2FUU5+hYhdnQ+\nQrJi9nKfz4fDZlM/5bAbf6sdOzofIVmRYbnZ0fkIyQpCUo2QrCAk1QjJCkJSjZCsICTVCMmK\nb5/+jnjzAjs6HyFZMXe5D4SUAyFZMf91pDL231dlR+cjJCvmL/c59n9DYkfnIyQrvljuQ+uf\ntks0xc8jJCt41k41QrKCkFQjJCsISTVCsoKQVCMkKwhJNUKygpAyKOb7YlK588ffCCmD+StA\nSFYQUgaE5B8hZUBI/hFSBoTkHyFlQEj+EVIGhOQfIWVASP4RUgaE5B8hZUBI/hFSBoTkHyFl\nQEj+EVIGhOQfIWVASP4RUgaE5B8hZUBI/hFSBoTkHyFlQEj+EVIGhOQfIWVASP4RUgaE5B8h\nZUBI/hFSBoTkHyFlQEj+EVIGhOQfIWVASP4RUgaE5B8hZUBI/hFSBoTkHyFlQEj+EVIGhOQf\nIWVASP4RUgaE5B8hZUBI/hFSBoTkHyFlQEj+EVIGhOQfIWVASP4RUgaE5B8hZUBI/hFSBoTk\nHyFlQEj+EVIGhOQfIWVASP4RUgaE5B8hZUBI/hFSBoTkHyFlQEj+EVIGhOQfIWVASP4RUgaE\n5B8hZUBI/hFSBoTkHyFlQEj+EVIGhOQfIWVASP4RUgaE5B8hZUBI/hFSBoTkHyFlQEj+EVIG\nhOQfIWVASP4RUgaE5B8hZUBI/hFSBoTkHyFlQEj+EVIGhOQfIWVASP4RUgaE5B8hZUBI/hFS\nBoTkHyFlQEj+EVIGhOQfIWVASP4RUgaE5B8hZUBI/hFSBoTkHyFlQEj+EVIGhOQfIWVASP4R\nUgaE5B8hZUBI/hFSBoTkHyFlQEj+EVIGhOQfIWVASP4RUgaE5B8hZUBI/hFSBoTkHyFlQEj+\nEVIGhOQfIWVASP4RUgaE5B8hZUBI/hFSBoTkHyFlQEj+EVIGhOQfIWVASP4RUgaE5B8hZUBI\n/hFSBoTkHyFlQEj+EVIGhOQfIUUr5ps/5xenO38opiOkaEvkQEhWEFI0QkIYIUUjJIQRUjRC\nQhghRSMkhBFSNEJCGCFFIySEEVI0QkIYIUUjJIQRUjRCQhghRSMkhBFSNEJCGCFFIySEEVI0\nQkIYIUUjJIQRUjRCQhghRSMkhBFSNEJCGCFFIySEEVI0QkIYIUUjJIQRUjRCQhghRSMkhM1f\n7tN+U/+bbZvdKdUUuhASwuYud7Vq/fuH6yRTaENICJu73Lui/Heub12OZbFLMYU2hISwuctd\nFufX7XNRpphCG0JC2Nzl7vx71uP/uLWXHSUkhLWXe7W/RI/jEUn5SDfLbkT3gaWIbun2PdLx\n8al8j6RypJtlN6K93NW/bXxL69azdqsqdgrLCAlh/eU+7VeRLZ129etI5WbP60gKR7pZdiMG\nlvtc3vo4JJ3CJEJC2OdyH9cRL7J+N4VNhISw3nJX+9vD0epY3Wra/DGStwipHulm2Y3oLPfp\n/mTD7vG89h8/+JS3CCkf6WbZjei8jnR7MDo0T8CNvzbEW4S0j3Sz7EZ0XkfaHKPH8YKs8pFu\nlt2IzutIU8aNv0WoaJt9croQEsI6y13t7g8t5S6iKB6RlI90s+xGtJf7UtaPHkVR/v16LG8R\nUj7SzbIb0V7udbG9PxZVuz+f+r7yFiHtI90suxGD3+pEfVvDW4RUj3Sz7Ea0l7ssHo8slezz\nA152lJAQ1l7uXbG+P7ic1uPf83wzhWWEhLDOcq+j3qnw1RSGERLCusv97/5tz1rwnd+fU9hF\nSAjLsNxedpSQEDZ3uYsi+s0LXnaUkBA2d7kPhKR7pJtlN6Kz3PtVTBgP5zL2KQkvO0pICGsv\n937S+0zPsU+Se9lRQkJY9wXZSc/XHVrvW42dwjJCQtj4/w0hPoVlhISw9nJviin/R9KsKSwj\nJIR1/zeK9R/vP/16CssICWHdL+2S/E+tXnaUkBBGSNEICWG8RSgaISGMkKIREsK6y33c3L+q\n28T/mKTpU9hFSAj7/P+Rbr8X8Y+fzJ3CMEJCWHu5D8W6/r/MD8U21RSWERLCum8Rqq7Pf5Ar\n1RSWERLC+m8RIqQgQkJYe7lXz0ekc7FKNYVlhISwge+RjhPfBT5lCssICWGd5d7wrwiNICSE\nfb6OVGz+pZzCLkJCGO9siEZICCOkaISEMEKKRkgI43+jiEZICCOkaISEsIHlPq0jfs7Yd1OY\nREgIG1ruijetDiEkhA0uN1/aDSEkhA0t92H8p5RLTGERISFs+MmGfaopLCMkhA2FtJL9SWNe\ndpSQEMYLstEICWGEFI2QEBZ4QVbyRVkvO0pICCOkaISEsM5y78vj7b+n6J/FN2MKw6yFNN/8\nSX9Xe9H2z58cdi5E3yPkZV+shbTEpL+r+6Vd/4b4FJYREsLai1a+HpH4V4QGEBLC2ou2K+rv\nkfhXhIYREsI6i7Z+frMZ+ePK50xhGCEhrLto/+p/ReiYcgq7CAlhvLMhGiEhjJCiERLCuovG\nDxobQUgI+3yy4coPGhtGSAhrLxo/aGwUISGs+4IsP2hsBCEhrP8WIUIKIiSEtReNHzQ2ipAQ\nNvA9Em8RGkZICOssGj9obAwhIezzdSR+0FgAISGMdzZEIySEtRdtI/uu76EpLCMkhPWf/k48\nhWWEhLD+09+Jp7CMkBDWXrRqsz4lnsIyQkJY90s7fmLfCEJCGCFFIySE8fR3NEJCGCFFIySE\nNYuW8N+p9bIvhISwbkhJcvKyL4SEMEKKRkgII6RohIQwQopGSAgjpGiEhDBCikZICHuHlOxn\ntnnZF0JCGCFFIySE8c6GaISEMEKKRkgII6RohIQwQopGSAgjpGiEhDBCikZICCOkaISEMEKK\nRkgII6RohIQwQopGSAgjpGiEhDBCikZICCOkaISEMEKKRkgII6RohIQwQopGSAgjpGiEhDBC\nikZICCOkaISEMEKKRkgII6RohIQwQopGSAgjpGiEhDBCikZICCOkaISEMEKKRkgII6RohIQw\nQopGSAgjpGiEhDBCikZICCOkaISEMEKKRkgII6RohIQwQopGSAgjpGiEhDBCikZICCOkaISE\nMEKKRkgII6RohIQwQopGSAgjpGiEhDBCikZICCOkaISEMEKKRkgII6RohIQwQopGSAgjpGiE\nhDBCikZICCOkaISEMEKKRkgII6RohIQwQopGSAgjpGiEhDBCikZICCOkaISEMEKKRkgII6Ro\nhIQwQopGSAgjpGiEhDBCikZICCOkaISEMEKKRkgII6RohIQwQopGSAgjpGiEhDBCikZICCOk\naISEMEKK9jshzTf/dK0jpGi/E9ICI80jpGjGrkxjp2vd/Lt+2m/qR/PN7pRqCl2MXZnGTte6\nuXe9WrW+Ml4nmUIbY1emsdO1bu5d3xXlv3N963Isi12KKbQxdmUaO13r5t71sji/bp+LMsUU\n2hi7Mo2drnVz73rnmc7xpz29rK6xK9PY6VrHI1I0Y1emsdO17ovvkY6X+hbfI6kcae10rZt9\n19etZ+1WVZIplDF2ZRo7Xeu+eB1pV7+OVG72vI6kcKS107WOdzZEM3ZlGjtd6xLddY/vZDR2\nZRo7Xeu+vOuHVVFsjkmnUMPYlWnsdK377nWk5zMOo0/auVldY1emsdO17quQdsWuul4vu+KQ\nYgptjF2Zxk7Xuq9CKov6ee+qWKWYQhtjV6ax07Xuq5Ca5xF4i5C+kdZO17qvQto2IfEWIXUj\nrZ2udfND2uwPx+Lf7Wa14y1C+kZaO13r5of0eo2oKEreIqRupLXTtW72XT+fD4fNpn7KYTfa\nkZvVNXZlGjtd63iLUDRjV6ax07WOkKIZuzKNna51hBTN2JVp7HStI6Roxq5MY6drHSFFM3Zl\nGjtd6wgpmrEr09jpWvdzIS3xL8QTkn+/F9KPjLR2utYRktOR1k7XOkJyOtLa6VpHSE5HWjtd\n6wjJ6Uhrp2sdITkdae10rSMkpyOtna51hOR0pLXTtY6QnI60drrWEZLTkdZO1zpCcjrS2ula\nR0hOR1o7XesIyelIa6drHSE5HWntdK0jJKcjrZ2udYTkdKS107WOkJyOtHa61hGS05HWTtc6\nQnI60trpWkdITkdaO13rCMnpSGunax0hOR1p7XStIySnI5c53QX+rTMlCMnpSGOnq+simYGQ\nnI40drq6LpIZCMnpSGOnq+simYGQnI40drq6LpIZCMnpSGOnq+simYGQnI40drq6LpIZCMnp\nSGOna/6Jc0JyOtLY6Zp/LCMkpyONnS4hqZhiAlt7TUgJR4oiJKcjjZ0uIamYYgJbe01ICUeK\nIiSnI42dLiGpmGICW3tNSAlHiiIkpyONnS4hqZhiAlt7TUgJR4oiJKcjjZ0uIamYYgJbe01I\nCUeKIiSnI42dLiGpmGICW3tNSAlHiiIkpyONnS4hqZhiAlt7TUgJR4oiJKcjjZ0uIamYYgJb\ne01ICUeKIiSnI42dLiGpmGICW3tNSAlHiiIkpyONnS4hqZhiAlt7TUgJR4oiJKcjjZ0uIamY\nYgJbe01ICUeKIiSnI42dLiGpmGICW3tNSAlHiiIkpyONnS4hqZhiAlt7TUgJR4oiJKcjjZ0u\nIamYYgJbe01ICUeKIiSnI42dLiGpmGICW3tNSAlHiiIkpyONnS4hqZhiAlt7TUgJR4oiJKcj\njZ0uIamYYgJbe01ICUeKIiSnI42dLiGpmGICW3tNSAlHiiIkpyONne4XI3X8PHRCcjrS2Ona\nGpn6YItNMYGtHSMklSNTH2yxKSawtWOEpHJk6oMtNsUEtnaMkFSOTH2wxaaYwNaOEZLKkakP\nttgUE9jaMUJSOTL1wRabYgJbO0ZIKkemPthiU0xga8cISeXI1AdbbIoJbO0YIakcmfpgi00x\nga0dIySVI1MfbLEpJrC1Y4SkcmTqgy02xQS2doyQVI5MfbDFppjA1o4RksqRqQ+22BQT2Nox\nQlI5MvXBFptiAls7RkgqR6Y+2GJTTGBrxwhJ5cjUB1tsigls7RghqRyZ+mCLTTGBrR0jJJUj\nUx9ssSkmsLVjhKRyZOqDLTbFBLZ2jJBUjkx9sMWmmMDWjhGSypGpD7bYFBPY2jFCUjky9cEW\nm2ICWztGSCpHpj7YYlNMYGvHCEnlyNQHW2yKCWztGCGpHJn6YItNMYGtHSMklSNTH2yxKSaw\ntWOEpHJk6oMtNsUEtnaMkFSOTH2wxaaYwNaOEZLKkakPttgUE9jaMUJSOTL1wRabYgJbO0ZI\nKkemPthiU0xga8cISeXI1AdbbIoJbO0YIakcmfpgi00xga0dIySVI1MfbLEpJrC1Y4SkcmTq\ngy02xQS2doyQVI5MfbDFppjA1o4RksqRqQ+22BQT2NoxQlI5MvXBFptiAls7RkgqR6Y+2GJT\nTGBrxwhJ5cjUB1tsigls7RghqRyZ+mCLTTGBrR0jJJUjUx9ssSkmsLVjhKRyZOqDLTbFBLZ2\njJBUjkx9sMWmmMDWjhGSypGpD7bYFBPY2jFCUjky9cEWm2ICWztGSCpHpj7YYlNMYGvHCEnl\nyNQHW2yKCWztGCGpHJn6YItNMYGtHSMklSNTH2yxKSawtWOEpHJk6oMtNsUEtnaMkFSOTH2w\nxaaYwNaOEZLKkakPttgUE9jaMUJSOTL1wRabYgJbO0ZIKkemPthiU0xga8cISeXI1AdbbIoJ\nbO0YIakcmfpgi00xga0dIySVI1MfbLEpJrC1Y4SkcmTqgy02xQS2doyQVI5MfbDFppjA1o4R\nksqRqQ+Wb4pivvlzmhpp7HRtjUx9sHxT2Fp3QnI2MvXB8k1ha90JydnI1AfLN4WtdSckZyNT\nHyzfFLbWnZCcjUx9sHxT2Fp3QnI2MvXB8k1ha90JydnI1AfLN4WtdSckZyNTHyzfFLbWnZCc\njUx9sHxT2Fp3QnI2MvXB8k1ha90JydnI1AfLN4WtdSckZyNFD3bab+r3rm12p1RTpDjmr4w0\ndrq2RgoerFq13ge6njfFF+88tbXuhORspODBdkX571zfuhzLYjdrCq6ShCONna6tkYIHK4vz\n6/a5KGdNwVWScKSx07U1UvBgnS+uPr/Sivoy7Jsv7YCvzbz2hy/mmeMmPCIB/n3xPdLxUt/6\n83skwL/ZD2/r1kPkqpI8JcCeL15H2tWvI5Wb/R+vIwH+ZXhnA+AfIQECCAkQQEiAAEICBBAS\nIICQAAGEBAggJEAAIQECCAkQQEiAAEICBBASIICQAAGEBAggJEAAIQEClgxpoX+ECb4seAW3\nLBrSr0zKHXU25wBCcjrnz9xRQuL6cjfpr8w5gJCczvkzd5SQuL7cTforcw4gJKdz/swdJSSu\nL3eT/sqcAwjJ6Zw/c0cJievL3aS/MucAQnI658/cUULi+nI36a/MOYCQnM75M3eUkAA/CAkQ\nQEiAAEICBBASIICQAAGEBAggJEAAIQECCAkQQEiAAEICBBASIICQAAGEBAggJEBAzpAOq6Lc\nVfXNXfnHTclpm/uYc9K31Md/yn8vF9jOalsU2/M165yRMoa0q392QHm/l+v65uoavCno3Py8\ngpyTvqU+/lP+e7nEdpb1Ic/hiTKt9oB8IZ2LbXX/i3N7vZ6K8nw9l8UpdFNy2vJ5ieWc9C31\n8Z/y38sltnN3n21XbK5L7eaIfCFtHlPdN3xXHG+3/hX70E05h2L9vMQyTtqS+vgPC9zLJbaz\nLKrnlAvt5ojsTzbcl2FTXK73v9M2oZuC0+2uz0ss46QtqY//sNy9zLyd9ZTldandHDurzPNV\nxfrabPr9l+Gbcs794+aYtCX18R8Wu5e5t/N6f9Q5XJfazRG5pzzcH3zzrsIPhPQxUa57mX07\n/xW3R9/rUrs5IvOUl/L+qEtIqSfKdC/zb+dhU9bfAf14SFW5riclpMQT5bmXi2zndXv/2u4H\nQ2r/6On14xn+8n1/h2+KTvr8Nf2kQ1If/2WJe5ltOzuq+7MNy+zmiJwhXVbrS/1bjydXLu/n\nWfo3BSd9LWv6SYekPv5L/nuZcTu77nd1md0cO6l8Ux2L9fPWvn66/3j/tnH4pqjnJZZ30kbq\n479kv5cLbOfjdaTL/Z0Ly+zmiHwhXV4Ln/ll6ecl5vqdDfnv5RLbWb+zodrcv0f64Xc2bIvi\n9QXXqr5R78TwTUnNl3hZJ31JffxG7nu5yHaWf02Ua7U/5QupaK18Vb9Jt/7t4ZuyE19HZko0\n6Uvq4zdy38tltvN2yNVhZKJcq/1pgec3AH8ICRBASIAAQgIEEBIggJAAAYQECCAkQAAhAQII\nCRBASIAAQgIEEBIggJAAAYQECCAkQAAhAQIICRBASIAAQgIEEBIggJAAAYQECCAkQAAhAQII\nCRBASIAAQgIEEBIggJAAAYQECCAkQAAhAQIIyYLztiy2x9eHZVHWvxYt7Y+WOs1fxqIbsHv0\nsbo8PjzebtdVEZIeLLp++6K8dVPdfnmUtC3qH+/99OqGgJbE4qt3eQf0yOf2hV353jdCUoHF\nV29X7B83qk39A73/Fbvb7/1r/piQVGDx1VsX597Hp+upWDcfEpIKLL56vUCq+im7sqj6f2eU\nxvIAAAESSURBVMxzDUti1dXrlXH/yu7a+tqOkFRg1dXrlbG6fWV3vZ6LVf+PKWhJLL56m9f3\nSMfq/hxe4/mqEiGpwOKrt2+etTvdH4X2r5Cev0tIKrD46r1eR1oXh/tXdpfn7z6/tiMkFVh8\n/bb1Oxsum/vTdedi8/zd5llxQlKBxTdg/X6v3a5o3rt6rJ+9G3rWjj1dAItuwb9NUazr57vL\n8vWbZfMW8OfHhLQkFh0QQEiAAEICBBASIICQAAGEBAggJEAAIQECCAkQQEiAAEICBBASIICQ\nAAGEBAggJEAAIQECCAkQQEiAAEICBBASIICQAAGEBAggJEAAIQECCAkQQEiAAEICBBASIICQ\nAAGEBAggJEDAfzUx/NWNmpV9AAAAAElFTkSuQmCC",
      "text/plain": [
       "Plot with title \"Histogram of Conditional Treatment Effects\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist(data_nsw$t_hat, main = \"Histogram of Conditional Treatment Effects\", xlab = \"CATE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0a2e46",
   "metadata": {},
   "source": [
    "### Check for Heterogeneity (2)\n",
    "\n",
    "A second analysis is to check for heterogeneity across some covariates. Since the trees produce splits such that treatment variation is maximized for the two next produced leafs as explained in the first section, one can check which variables have been used quite often to make splits by the trees. In order to obtain these variables the \"variable importance\" function of the [grf](https://grf-labs.github.io/grf/reference/index.html) package can be used.\n",
    "Here, the variables \"age\", \"education\" and \"re75\" have been used the most by the trees. Therefore, it seems plausible to check for differences in CATE between different levels within these covariates.\n",
    "\n",
    "Indeed, the boxplots below show some heterogeneity \"when we change a single covariate, while keeping all the other covariates at some fixed value\" (Athey et al. 2020). Especially people around 30 years old and people with a higher degree of education seem to have particular large treatment effects. Furthermore, the treatment effect seems to be negatively correlated with the pretreatment earnings, that is people being on the lower side of income before treatment benefit more from the jobmarket training. This finding implicates that the program addresses the people who should in the end benefit the most from it. On the other hand, it also implicates that people earning more before treatment should be addressed by some other kind of jobmarket program, which might also have a positive effect on the higher income group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2efcf221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1</li>\n",
       "\t<li>2</li>\n",
       "\t<li>7</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 2\n",
       "\\item 7\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1\n",
       "2. 2\n",
       "3. 7\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1 2 7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'age'</li>\n",
       "\t<li>'education'</li>\n",
       "\t<li>'re75'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'age'\n",
       "\\item 'education'\n",
       "\\item 're75'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'age'\n",
       "2. 'education'\n",
       "3. 're75'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"age\"       \"education\" \"re75\"     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Variable Importance\n",
    "select_index\n",
    "colnames(X[,select_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0e0ebf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAM1BMVEUAAAAAAP9NTU1oaGh8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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot(data_nsw$t_hat ~ X[,1], ylab = \"Estimated CATE\", xlab = \"Age\")\n",
    "lines(smooth.spline(-17 +X[,1], data_nsw$t_hat, df = 5), lwd = 2, col = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62d8e68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAM1BMVEUAAAAAAP9NTU1oaGh8\nfHyMjIyampqnp6eysrK9vb3Hx8fQ0NDZ2dnh4eHp6enw8PD////UNI3wAAAACXBIWXMAABJ0\nAAASdAHeZh94AAAgAElEQVR4nO2d6WKiMBRGGdSqdX3/px3FDVsqWb6Em3DOjxlnGu6NJKeQ\nRWzOABBNM3UFAGoAkQAEIBKAAEQCEIBIAAIQCUAAIgEIQCQAAYgEIACRAAQgEoAARAIQgEgA\nAhAJQAAiAQhAJAABiAQgAJEABCASgABEAhCASAACEAlAACIBCEAkAAGIBCAAkQAEIBKAAEQC\nEIBIAAIQCUAAIgEIQCQAAYgEIACRAAQgEoAARAIQgEgAAhAJQAAiAQhAJAABiAQgAJEABCAS\ngABEAhCASAACEAlAACIBCEAkAAGIBCAAkQAEIBKAAEQCEIBIAAIQCUAAIgEIQCQAAYgEIACR\nAAQgEoAARAIQgEgAAhAJQAAiAQhAJAABiAQgAJEABCASgABEAhCASAACEAlAACIBCEAkAAGI\nBCAAkQAEIBKAAEQCEIBIAAIQCUAAIgEIQCQAAYgEIACRAAQgEoAARAIQgEgAAhAJQAAiAQhA\nJAABiAQgAJEABCASgABEAhCASAACEAlAACIBCEAkAAGIBCAgg0gNQGEE9HK9OBOkAFCCSAAC\nEAlAACIBCEAkAAGIBCAAkQAEIBKAAEQCEIBIAAIQCUAAIgEIQCQAAYgEIACRAAQgEoAARAIQ\ngEgAAhAJQAAiAQhAJAABiAQgAJEgCZIHVhUEIkFaZtKWiARpmUlbIhKkZSZtiUiQlpm0JSIB\nCEAkAAGIBCAAkSAtM2lLRIK0zKQtEQnSMpO2RCRIy0zaEpEgLS5tqfkqyUlBJDBEuQ2PSGCI\nchsekcAQ5TY8IkFavNqy3IZHJEiLvi1NzkwgEqQlYVt+Cj00EZjSP0SCtEwlUuTxviASpCXh\nGAmRDKQAiyCSFkSaKbqGR6RMKcAiiKQFkephonUkRMqUAjLBrF2O9NOlgEwgUo7006UAXwIX\nNBEpR/rpUkAwujnqhKERKVMKCGaia4xfaUTKlAKCMSNSbCREgilBJE0sRAIPWEfKkX66FJAJ\nZu1ypJ8uBWQCkfTp95tVt/ywWu9TpYD0JJz+9mOmIp0WvaW8ZZIUkAPWkTSxQtOvm/b70L06\n7tpmnSIF5MDMrN1MRWqbw/P1oWlTpIAcmBEpNlKhIr1tzfq8TwuRLINImlhckcAD1pHU6S9j\npN2xe8UYaUYwaydPv+zN2i1OSVKAORBJn36/7taR2tWGdaSCYR1JE4udDTOHdSRNLESaOWZm\n7WYrEluEqsCMSLGRChWJLUKVgEiaWGwRAg9YR1KnZ0F2ljBrp07PFqFZgkjq9FyRKoF1JE0s\ntgjNHNaRNLHYIjRzzMzazVUktgjVgRmRYiMVK5KlFBAMImliJTqPxr7uHUSwjqRPzxahGfKh\nLQe+38LrKy9mOkZii9AsCRQh9viKRWKLUCXIptYQKQgWZCsBkTSx2CI0c2Stg0hBcEWqBDMi\nxR5WqEhsEaoERNLEYosQeJBwjBR7WKkisUVojjDZkCP9dCkgE4iUI/10KSAYpr81sWLTb9tm\nsU2bAlKCSJpYwekPq6bdnjdsESocM7N2MxXp0Bm0br5O5+Oq+XhNQiTLmBEp9rBCRfq6rh2t\nbyuxp2aRIgXkAJE0seK2CDWr3j/UKcAerCOp09/c+b7d07FFaC4w2aBO/3UdHd04fbFFaC4g\nkjr9qX3ezzWfL0iIZBqmvzWxwtOvH/q0H69HiGQbRNLEYmfDzDEza4dIBlJAMGZEij0MkWBK\nEEkTC5HAA9aRcqSfLgVkgsmGHOmnSwGZQKQc6adLAcEw/a2JhUgzB5E0sRBp5piZtUMkAykg\nGDMixR6GSDAliKSJhUjgAetIOdJPlwIywWRDjvTTpYBMIFKO9NOlgGCY/tbEQqSZg0iaWIg0\nc8zM2iGSgRQQjBmRYg9DJJgSRNLEQiTwgHWkHOmnSwGZkInUuOAVG5GgHHQieSVDpEwpIJiJ\npr8RyWQKCAaRNLEQaeZMNGuHSCZTQDCIpImFSDMHkTSxEAk8YIyUI/10KSATiJQj/XQpIBOI\nlCP9dCkgGKa/NbEQaeYgkiYWIs0cZu00sRBp5iCSJhYizRxE0sRCJPCAMVKO9NOlgEwgUo70\n06WATCBSjvTTpYAX/U+WuhT3Cx4ZCJEiQKSMdBb5qIRImliIVBdN70+PA2SZXQshkskUcKf5\n8bf7EbLUboUQyWQKuINIEhBp7viLFBbf70cDhRDJZAp44D1GCgnv+6OBQohkMgU88J618wwf\n9KOBQohkMgW8YB0pHkQCXxBJEwuRZg6zdppYiDRzEEkTC5FmDiJpYiESeMAYKUf66VJAJhAp\nR/rpUkAmEClH+ulSQDBMf2tiIdLMQSRNLESaOczaaWIh0sxBJE0sRJo5iKSJhUjgAWOkHOmn\nSwGZQKQc6adLAZlApBzpp0sBwTD9rYmFSDMHkTSxEGnmMGuniYVIMweRNLEQaeYgkiYWIoEH\njJFypJ8uBWQCkXKkny4FZAKRcqSfLgUEw/S3JhYizRxE0sQKT7/frJorq/U+VQpID7N2mlih\n6U+L5sUySQrIASJpYoWmXzft96F7ddy1zTpFCsgBImlihaZvm8Pz9aFpU6QAL5rfJEgS9KOB\nQoj0OK756x+yFBBGyvONSOr0XJHMgkjR5B0j7Y7dK8ZIxpBNaPuVRqQwlr178cUpSQoIQqeG\nE15pEek3+3W3jtSuNqwjFUzWawwixYBIlkEkTSxEmjmIpInFFqHqMLzEiki/YIuQWRApmrzT\n32wRsgkiRcOCLJheGUKk38c1f/1DlgLCQKRouCKBL4ikiRUxRmKLUA0gkiZWcHq2CNUBImli\nRawjsUXIJszaRcPOBkAkAXZESvxBTfgAIkWT99aOLUI2Yfo7mowisUXILIgUTd7pb7YI1QAi\naWKxIDtzEEkTKzQ9W4QqAZE0sbgiVQezdtHkHSOxRcgmcxfJ65EtY5mdCT7rbBGyCiJFm5R3\nHYktQjaZ+/R3YVckUymgx9xFEoBI4AsiaWIFpz99Nc1ydw/C9HexIJImVmj6U9vdaq5uQRCp\nWBBJEyt8+nt7sWnbdtvsEMkSc5+1E5B1Qbb769gujohkC0SKJqNID3dOyyUi2QKRosko0qJ5\nLMIuloiUBv/1j9thfkkiAyFSXPpt83V/dWyWiJQYr1OISNHknP5eP+3ZjfyiRKRoEp5CRNLE\nCk9/WD1eHb8QKS2I5FM6nqwiWUpRO4jkUzoeRAJm7X7y74LD8U6xpIcYTAE9EKnPv3+IBEEg\n0pMgixzzxR9iMEXtMP3tU/rOv1CNEKlaEMmn9JUIixzzxR9iMEXtMGvnUzr8ls4nX/whBlPU\nDiJ5lI61yDFf/CEGU9QOIrmWjrul88kXf4jBFNBjxrN2Eosc88UfYjAF9JirSCqLHPPFH2Iw\nBfSYpUiaWzr3fIpDDKaoHaa/PyO1yCGf5hCDKWoHkT5wt0jZzRCpUpi1+4vXLR0iwSiINMjb\nwAiRYJQKRfJ6QPdg7B8DI0QCLWXM2kWK9Ht6AZFAS/0iDc51IxJoKUMkr/xvpf+Y60YkGIXp\n7wd/rxghEoyCSDc+LbwiEoxS4aydT+Hbq5HtC0ZEenvGo9OTcb1TQDCINL4LyJRId4MQyRhz\nF8llLx0igZbqZu3ctqQiEmipSyTnjd2IBFoqEumx8up3IxgPIlWKbPrba0PB1CK9LkaI1E8B\nwehE8jl+UpHebukQqZ8Cgsl6t2ZBpICd3WZEGt4uOE2t4J15ifSw6G0dyT20AESqlDmJNDQy\nKkikhCBSXkoeI/0xMkKkTCmgR7ki/TkyKkgk7d3cYArIQ6EiffrMKyL1U0Aw9U9/f/7MKyL1\nU0AwlYs0+plXROqngGCqnrX7czcdIg2ngGDqFcntM69FicQ6kl1qFenz1m5Eiq4VRFDKGMnj\nM69FiSSsx3AKyEMZIjl8zgiRhlNog354nODMKUEkz8+8IlI/RYnRjVDX9Lfrh14RaThFidGN\nUJNIN4381ECkfooSoxuhmlm758WoWpH6HNZtdFVGUpQS3QiViNS7p6tfpONm0TQFiTQLqhDp\nbWRUuUin74tFzXInqs9QinmTY7LR5Bjp5+OAqhbpe9m17FFWn98p4E7Ck2JQpN9Do3pF2n1d\nHGrXB/2vSMZIA8xIpP5sd/0itVeL9ucU03eINIBftQue/v43PDSqVqSmWT9eyKrzI0UaEMmn\ncGaRfi291i8SVyTLlDlrN7CDoX6RHmOkPSIZpESRBvcBzUCkM7N2dilPpD+2081DpMc60op1\npOTUPWv3567UuYh0ZmdDJmoWyeXT4/WLdGavXQ7qFcnt0+OzEEkMIg1Q6/T3yEeN5iDS8Wt7\n/eu02Mrq8zNFChDJp3BikUY/sTcDkY5ts7r+vbuMkLTzdogUTRmzdg4ffJ2BSIvm69S92C+b\nhaxGbymSgEjqQIEi+T2GoVqRds3m+X+r5ltTn/cUEIx9kXwfw1CtSF/N6fl/x2apqc97CuhR\n1ayd69NM5iDS284gHhCZnIpE+vmZPVnsnkguuOR3JEKktlSRCtW0GpEGvqhSFbtIkb6a176g\n3W3+TgUiDVDJ9PfQZ/ZUscsU6fCa9D62JU02IJJPYa1I3o8zmcEY6bxu2s3h8vdh02rnGhAp\nHpOzdgGPM5mDSOfN8xr5JazSGZEEGBQp6HEmsxDpfFxfP4+02jjua9hvVp12q+6DtdpawTvm\nRBp40iMiBXFa9IZ5n28FEWmAomft+mMjRIpLfxlSfR+6V8dd+3hwijZF1RQs0vvqKyLFpW+b\nw/P14fMHARkjDVCsSFHPBUKk38c1f/1DlsKxIkmjJ6PQ6e/I5wIh0i+4Ij3yh60MFinS0JY6\nRIpLfxkj7W7TexOPkaYW6UnKipiYtRvemYpIkemXvV/Bi9OnkohkJ3a4SH9t8Eak2PT7dbeO\n1K42rCNdqVqkvz8ngUjvh6TbAIhI8aVlocNE+vRxI0R6PwSR8lKOSCOf2kOkgUNW7fWzFPvW\nabOdkS1ChWpaikijH35FpN+HrO9T2ofPs3AdZrYIzUKkqaa/1c8FmolIzzs6h1s7M1uEzIiU\ncow0jUj65wLNRKT2eUUaf2QxC7I/qW3WLsVzgWYi0uUqcx3uXK4wm7+Kv44bvJSpauXB3EVy\n+hS2f/9N81ygmYj0XGR1eGSDmSuSGaYSyet4xx6Z6rlAcxHp/H2diHP6eiTZFiGvX6iWSTlG\nig3k139/ffhVFno2Inmg2iLkd2tSDXZFGvjwqyo0Ig0h2iIU61GhjlkVafDDr26hvVqycpF2\nq+tbXfFtFMmR3QhKReo0Cr3GINKT5e2tCr7XJd99mRmRUo6Rsoj02MSASLEibZvl6fpWt04P\n5Cppi9CHFs1bEX1slUivvUAJRz0zGSO1zem2JOTQzQrdIpSwLkWLlOm5QDMRqbutcxTJzBYh\nPxBpiGzPBZqJSIv7Feng8JV9Ey3Iet2HJ65LVGhDs3YZnws0E5HuY6TLFWb8+5gn2iIUe0bN\nXB0/XWPko/ZP/Tfrc4FmItJ55TTm6ZjqiiQqMzlZ5uHGS2d+LtBcROrWkZqVy5e6TPQUIUT6\nWSiqdO7nAs1GJA+meYqQYZFkY6Rs/Tf/c4EQaYBJniJkeIxkaPrAqfSfH5RApFiRniPYdvyD\nfYEpcsRCJIfSHz5vhEgqkY52nyKESD8LhZX+9LE9RIoRafc2tzq+jpS2VlGxihBp0jHS50+/\nIlLUFam/5WcxMupJXquoWBOJ5MeEIk34gK05iHQ+u+wMCsGSSGaYTqTRhzEgUs5ZO/ddOYg0\nxFQiOTzTBJFkIu3Hn36yRaSotNOINPWT6uYi0tpJjBuH1mEjUWitomIVMdkQGyio//o+qS7r\npr8PhUsT6eWRy3OEXB5sHFqrqFiINFy6+xi5lxqIFHZI23yfl83xuGycZu22vX2r4lpFxYoV\n6VNviQztRBqR7o+qQyQXBLN2m8vV6OCy/TssRY5YgR0hLFmC0ilEej6qblo1ZiTS7vpZpEp2\nNvg1bViyUPKK5PWoOkSKFWl1ubU7NovzHpHcjw8kp0iej6pDpFiRdleBuo9HOH3TWEiKHLEQ\n6Y23KW9EciJSpMsA6fLHV+M6HReSIkMsmUh+GB0jvT8OH5GciBUpDYiUIJDjm/z5OHxEcgKR\n3srMXqSwZz4iEiK9l8k7RrIn0mtwhEh+xIq0bscXVyJTZIhVhEjpx0iDcwyI5ESkSOvfa3IK\nZiKSH6lFinh4KiLFitQ4PBgyAERKkPb1Jof493NfnU9sRIoXSVaTv1LkiJVFpMjdR2lF+r09\n1Sc2IsXf2n18Pl0oxYokq4jfz2JFGtrlHVRtRAo9ZLnUflffQIoMsYoQKfawP9/k4Gf3EMmP\nWJF2v36DKUAkfeg/3+TwZ/cQyY9IkTZOd/dRKXLEyjNGigsdfdjwm5Q8PBWRYkVy+TqXABAp\n18eA/vwoOSL5ESkSs3buyRJ2hNAe+eGJDIjkR/StHbN2rsnMifTxAUGI5EfsZMNmKX3E6lCK\nDLFmKZLwKcSIFH9rx2RDkook779jz9lCJD8Q6a3MbETSPoUYkaJv7dKASGn7r/opxIiESO9l\nZjFG0j+FGJFiRLrezXFr557Miki+TyFOVhFEuv+NSF7JbIjkphEi+cKt3VuZ2kW6ferItXTC\niiQqjUjpUiDSq9DtclSqSD6bpkoTqbZvNY8VSVaRFNX+9YAgWewsInn9qFSRJv5Wc6e9Li75\nahbJ62neiORJhEiGvtX837+/p3QRqcPzad5FiBR7mBGRbH2r+Z8uMUY6BzzNG5ES5PtwiKmP\nUQy7hEghT/NGpAT5EqZXpxhwya8j+E0NeVV8MpFCnuZdhEiVjJE6tpex0XEhvrOLeoc/XZq9\nSEFP80YkTyJF6r4fqXtq8dRjpD5vLiUUybO0T0Vk/Tfwad6I5EmkSMvm+3xoFudva98h++8p\nk5mOMIVI/YszIoWUcUUw2XC4fsuYwb12/wYGTGP5KhMp/GneiOSJQKRVszMp0hVHl+oU6cc7\nr0+k2MMMibRsDrumPdu7tXvh4lLxIg3x6znEGaqNSIGHdLsbNteW3MmqdJa/w1GXKhRp4HHe\nGaqNSKGHbNvue5gX36L6DKSQxPrsUnUi/RvwqD6RKhojJUL6Dt861+/ulbiPTTBG+uN3BiKF\nlHFlRiJ9cskrsW2R/rz0IlJIGVciRHqbqDM6a3f+ddsz7JJXYssifbiBRaSQMq5Ei3TvhIZF\n+vU/vxeYKhHp85wKIoWUcWWOIp1/uVSFSBNOTU4kUuxhiCSJ1XOpApEmXSxDpDmLdH65VLxI\nLvs3EEkUWhWrIpHOP2/yihTJcUthfSIxRnJNkSdWz6UCRbKwMxeREOle5jEr7hXRgEg/bk1l\nFemVdiEwtFdprx+VJdLguZyoVlGxer/ajdwjOZXOciFV/ShvRRAptFZRsR5l3FwyIlKvqmb6\nr5mKlCRSQqYS6Xmz9NElEyK9VdJM/81bkdjDEEkd60fTjrg0vUg5Z+29MFMRRJKnCBDp/Pkm\nb2qRfg+NzPRfMxVBJHmKMJHOH1yaVqShVS8z/dfMPSYiyVMEi3Tl35BNU4o0PDQy03/NVASR\n5CmiRDr3XBrY4ipfY/ks0k+nESmuJoikjjXatG82TSRS1ksjInmCSG9lPhb+dW3KJtIfwzVE\niqsJIqljeTRt36YcY6Tfd5aBoSsUKfYwRFLH8m3aT707KvabSKNZJhIp9ihE0qfPkCKFSB2O\nNgWJ5BYbkeIOQyR1rPAeOd7jPUX65+ind+gKRWKMlDNFWpE6PvZ999hvDmWotltp1Y/yVgSR\n5Cly9ch/Q7jG/q0iIsVlQyR1iqw9ctCmzzdrbz99m2zIV+1PpVU/ylsRRJKnmLJHjnn14TqE\nSHHZEEmdwkyPbP6+/ftd2E61VT9KUJHYwxBJHSuXSO6F7VTbC8+KeO0M0dcEkdSxEOlDTXxI\nebPmByKpU5jpkXZESnchyCsSY6ScKRBpvJCs/6Yc9fgFQiR1CkTyKRQZyExFEEmeApF8CkUG\nMlMRRJKnQCSfQpGBzNxjIpI8RakiqT8zWMQYSdfwiKRO4SdSwv5bjUhhOfJWBJHkKWLPqOz3\nLyJlrAgiyVMkPKOeIvmokXeMVKhIjJFypkCk8UJmxkh+IFLOFIjkUygykJmKIJI8RaljJHVo\nREpXkbBYiOQTGpHkxzuVRiR1CkQaL2RmjMSsnRZEsixSWI68FUEkeQpEGi+kE8lvRiVdRRBJ\nnsLOrJ1XxDJFio3NGMmJ/WbV/UZarfepUoTFQiQfUpaWha5YpNOid3VfJkkRGmvuIvmBSJpY\noenXTft96F4dd22zTpEiNNbcx0h+IJImVmj6tjk8Xx+aNkWK0FiI5ENCkRgjuRzX/PWP+/84\nzev4p40sMweRirjG6CMVKhJXJJ+KGBYpIYjkwGWMtDt2rxgjjUdEpPSRChXpvOzduy1OSVIE\nxpr7rF1KkRgj6dPv1906UrvasI40FtGwSEWMqKoWaZIUiORTSB8IkXKkz5AicvfXLMZIfiCS\nJlZhIsVGR6S4QIyRcqSfLoUzOpG8Lo3VjJEmCo1ImVI4IxNJlvZ3Gcuzdl4gkhYzDXtOKpLs\n1sTpYodI6bLNU6S8g4UcIgUeH1bYE8ZIOdJPkgKRogqXMaJCpPQpECkORNLEmplIJYyRAo8P\nBJE0sRDJK1COWTtdWhdYR9LEKl4kPwoVSZ4sQdqUoREpUwpnECkjiKTFQMO6rMNYHiN5YeB8\n30AkLZbGSLGBSphsYB0pGkRKHag+kYoYUSFS+hSIFAciaWIh0jNQwi1uiBQXGpHSpzDTx2Ij\n1ScSYyQtZmaRfLEjkjxZgrQpQyNSphTWMSxSQhBJi5mGTYuZWxMz5xuRtBQ7RvLDzGQD60jR\nINKEoQsVqYgRFSKlT4FIcSCSJhYiqUIjUhyING0KM30sNlJ9Itn5ReTLHEVKiB2R5MkSpE0Z\nGpEypbCOYZESgkhazDRsWszcmpg534ikpdgxkh9mJhtYR4oGkSYMXahIRYyoECl9CkSKA5E0\nsRBJFRqR4kCkaVOY6WOxkeoTyc4vIl/mKFJC7IgkT5YgbcrQiJQphXUMi5QQRNJipmHTYubW\nxMz5RiQtxY6R/DAz2cA6UjSINGHoQkUqYkSFSOlTlCFS3JO+yniTkSDStCkK7WNF9N/Y0rLQ\niJQshd9v9MAc8oihscsUyc6tsS8zEikhnrddgUnkEQNDm6lIbCREmiVF9N9IEEmLmYZNi5m3\nWWFFEClTCguYGVEVWhHGSAZSWKDC/htbWhYakTKlsECF/Te2tCw0ImVKYQFEigORDKQojyL6\nb2RpxkhaEGmAMtXwg1k7LYg0QBH9NxJE0mKmYdNi5m1WWBFEypTCAoVOf/vBGClH+ulSWKDC\n/htbWhYakTKlsECF/Te2tCw0ImVKYQFEigORDKQojyL6b2RpxkhaEGmAMtXwg1k7LYg0QBH9\nNxJE0mKmYdNi5m1WWBFEypTCAoVOf/vBGClH+ulSWKDC/htbWhYakTKlsECF/Te2tCw0ImVK\nYQFEigORDKQojyL6b2RpxkhaEGmAMtXwg1k7LYg0QBH9NxJE0mKmYdNi5m1WWBFEypTCAoVO\nf/vBGClH+ulSWKDC/htbWhYakTKlsECF/Te2tCw0ImVKMSGBX11RRP+NLS0LjUiZUpRHEf03\nsjRjJC2INECZavjBrJ0WRBqgiP4bCSJpMdOwM8HM+UYkLWYatlyKWkcK/OpQxkgGUtQO60hx\nx/uCSMVQRP+NLS0LjUiZUpRHEf03trQsNCJlSlEeRfTf2NKy0IiUKUV5zEENHVWLtN+sugmZ\n1XqfKkXFmBGpCCoW6bToTW4uk6SAMCo83xWLtG7a70P36rhrm3WKFPCkqHWkBKErFqltDs/X\nh6ZNkQKesI4Ud7wvGUV6W6z+vHKNSAMU0X9jS8tCVywSV6Q4iui/saVloSsW6TJG2h27V4yR\nQiii/8aWloWuWKTzsjdrtzglSVEzc1BDR80inffrbh2pXW1YR/LHjEhFULVIllJAjwrPNyJl\nSlE7s19HciFTXXSH3GGLUD7mvo6UG7YIFUOh/ddMRdLCFqFiKLT/mqlIWliQLYZC+6+ZiqSF\nLULFYKZH0joDcEWyTtrJpnsOecTZwRYh4HwLYItQpcx9HSk3bBGqFNaR8sLOhkox03/NVCQt\niFQpZvqvmYqkhS1ClWKm/5qpSFrYIgSG1CgXO1uE0q6UwCc439GwIAucbwFsEaoU1pHywhWp\nUpw+IRq2+8jMiMpSN2GLUKWY6b9mKpIWtghVipn+a6YiaWGLUFUkfjDBPUnC0lZCe8POBvCF\n1hkAkQAEIBKAAESCtDBGEh5iMAUEw2TDAFl3NjhPJlk6Q/ATRBogo0hbRKoDRBog563dof38\n4QlBCsgAIg2QdYx0+LwxSJECkpFjrbdc8k42bHv7VhOlAJgCZu0ABCASpIUxkvAQgykgE4gk\nPORHgNEIls4QxIFIwkN+BECkGYFIwkN+BECk+rH3wai0IBKAAEQCEIBIAAKY/oZisdRNEAmK\nxVI3QSQoFkvdBJGgWCx1E0SCYrHUTRAJQAAiAQhAJAABiATFYqmbIBIUi6VugkhQLJa6CSJB\nsVjqJogExWKpmyASgABEAhCASAACEAmKxVI3QSQoFkvdBJGgWCx1E0SCYrHUTRAJisVSN0Ek\nAAGIBCAAkQAEIBIUi6VugkhQLJa6CSJBsVjqJogExWKpmyASFIulboJIAAIQCUAAIgEIQCQo\nFkvdBJGgWCx1E0SCYrHUTRAJisVSN0EkKI3mN1NXCZEAJCASgABEAhCASAACEAlAACIBCEAk\nAAGIBCAAkQAEIBKAAEQCEIBIAAIQCUAAIgEIQCQAAYgEIACRAAQgEoAARAIQgEgAAhAJQAAi\nAQgwKhJAYQT0cr04sfhVKWFpMxUptNpmKjLT+y4zZ9RMRQqttpmKINK0pc1UpNBqm6kIIk1b\n2qSQOkwAAAdRSURBVExFCq22mYog0rSlzVSk0GqbqQgiTVvaTEUKrbaZiiDStKXNVKTQapup\nCCJNW9pMRQqttpmKINK0pc1UpNBqm6kIIk1b2kxFCq22mYog0rSlzVSk0GqbqQgiTVvaTEUK\nrbaZisxUJIDyQCQAAYgEIACRAAQgEoAARAIQgEgAAhAJQAAiAQhAJAABiAQgAJEABCASgABE\nAhCASAACEAlAgDGRTl9N83XwOWLv/A78no9+uNbk6BXZNfZp3Tbt+uRYkfOl9HLnVHL7qIBT\ngm0z9HK09HYxHvtR2K05+9nHm/NR2u2UP2P7tGcIxkRqu5PjYdKpdTbDq7PvurKtW29/eNQ6\nlT7e3mTr2KrLrvTGoeTh8eZuhywcS7+9HC29djgxz8JOzdnPPt6cj9JuzfmM7dWeIdgSad18\nXf9YuR+xcr/E+IQ9t+3hfFo1a49Dds3eqdxXF7V7qw5sm+Xp+pt9/JfLob2fi31zqfzlXx+r\n8yz99nK09KH5Ol0r9anyz8JOzfmWfbQ5exVxaM5X7ID29MOWSG1z/ZXh8fU03+73alun3+rP\nuNdTfnK8xnScWkdR7zV2rPiy8+E43gUuxj377/VO8Pvj+32V7r8cL70ar/yrsEtzvmUfbc5X\naZfmfJUOaE9PbIl0w/3tHsf7wJNts3WvgssV4AerxvG+4X734vguH9otRwuuz8/Ofr1r/Pwr\n+1W6/9Kh9FutnAp/fqP90uPN+Srt0pyv0gHt6YlBkdbuPX7ZHJ1FWjW7r8sw2a3wojlv2u4u\nxpWD823D5n5r53aBdL5+HX6W/XjIq3T/pUPpjtMnr38UHmnOfunx5nyVdmnOV2n/9vTFnEiX\nq7vzjeym+Xa/D1zdBqejv9k7mmblPntwD+/cStvrGLx1/G2x6C4ve6e36SHS+88dor8V2Taf\npxHfbtZGm/NR2q05nyI5NefzXPi2py/mRNquWtfBTHfz4ixSc2mm88nxctdcx+uXIb7zsOrg\nOHdwZeM8D9cVXp3OB7c72FwiHceGg6/CLs3Znz5wFsmxOZ+lPdvTG3Mina83tG6/rRfX2UzP\nL849jc0K37jN2R7dCl9Zj/yO7rG9/o4+ub7J2xSy2+RkJpFOreN14MboO33cfrk15497zJEW\nep4Lz/b0xqJIjpMrX13f9f0GarfyfjNr5+cMgguL7ibQ0ehOuXbjVpPnZFn/X2OlXYq+F1mO\n1vxHZx9pzltp1+Z0n/Xo/dy7Pb2xKJJzZw/5Mne30g6zvG/4LFKFNOrBSbu3WbvjWJUCRTou\nlqNLySGd3bU5g0TybU9/bIl0W3hwvAJ7ivSI7dTjN92vx6Pj1ITf3PrtguG6pnGr9tap2vcz\ncav8bmyUHybSzuWcvK0jjTZnkEiOzfl2Stzb0x9bInVL4aeVz4qP8y+ZdTc0cRzLXBq/20/w\n7Rh85bFOcanI6V4dp9KXU7JfONXkfi6cdjYEiuTWF58rw07N2c/ufGvn2JzPavu1pz+2RLpv\nzvL5veEs0ukW23FufeNXkYX75PdjK5xj7Hu1na6jj3Ox8JkZ/vFypPSX02Xj8WO35gwSybE5\nX1Prvh3LE2MiXfctLzyuRz63vSev2Lul8+qtVy2udJuzXQsfL3135TYl+KjFySlBkEhu91/P\nHzud8iCRHJvzGc+vPf2xJhJAkSASgABEAhCASAACEAlAACIBCEAkAAGIBCAAkQAEIBKAAEQC\nEIBIAAIQCUAAIgEIQCQAAYgEIACRAAQgEoAARAIQgEgAAhAJQAAiAQhAJAABiAQgAJEABCAS\ngABEAhCASAACEAlAACIBCEAkAAGIBCAAkQAEIJI5Br6V2OULAXeuBSEFnHhzhIm0aBwLQhI4\n8eYYkMH9O15hIjj95kCkEuH0m+NdiXXbrLv/anr3bpf/XB6vL3ar5vZl3fdbwduPt4v79303\nzXHVtJus1Z8piGSON5GWV0FWP0Tq/rM9nc+b21hq/S5S9+Nm2ZVury8xKT2IZI7+XMN30x7O\nh/ZdpO9meTp/3fT5vv6zOb//+HbM9/Wfl5LbZjHl25kJiGSOvkirZn/5c/cuUvefp6Z9HXB+\n//GuO2Z5/ef+zPApC5xjc/T7/f31u0j9AsfdZvlDpMFjIDGcY3P4iLR8XrsQaVo4x+bwEOmr\nWWx3R0QyAOfYHP1+fxvv7J9SdK+WzzFS938/RXqMkVaIlBHOsTn6/X73mrVbNNvzqRsPba9z\ncevbrN3+fHiMkY7ngVm7nwEhEZxjczTv03YXvm76PFaUXutI63vB/dWz5yWqv450PiNSFjjH\n5njftLp57Gy4vvp67Gy4KNXtbLgottx3d3H7xVOk87Z97mx4/QlJ4RwDCEAkAAGIBCAAkQAE\nIBKAAEQCEIBIAAIQCUAAIgEIQCQAAYgEIACRAAQgEoAARAIQgEgAAhAJQAAiAQhAJAABiAQg\nAJEABCASgABEAhCASAACEAlAACIBCEAkAAGIBCAAkQAEIBKAAEQCEIBIAAL+A5U0epmE8pgG\nAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot(data_nsw$t_hat ~ X[,2], ylab = \"Estimated CATE\", xlab = \"Education\")\n",
    "lines(smooth.spline(-2 +X[,2], data_nsw$t_hat, df = 5), lwd = 2, col = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bafaf80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAM1BMVEUAAAAAAP9NTU1oaGh8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\nOt2TYL0qrgAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_nsw$re75fac <- factor(ntile(data_nsw$re75, n=10))\n",
    "boxplot(data_nsw$t_hat ~ data_nsw$re75fac, ylab = \"Estimated CATE\", xlab = \"Pre-Treatment Earnings \")\n",
    "lines(smooth.spline(data_nsw$re75fac, data_nsw$t_hat, df = 5), lwd = 2, col = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9703631",
   "metadata": {},
   "source": [
    "## 4.) Conclusion<a id=\"conclusion\"></a>\n",
    "\n",
    "In this project I compared the performance of causal forests in identifying heterogeneous treatment effects. Causal forests can be thought of as a matching estimatation  method, choosing the closest neighbors in order to construct a counterfactual, i.e. matching observations that have fallen in the same leaf. Of all the considered cases causal forests perform exceptionally well when some of the regressors are correlated or some higher degree polynomials and interactions have been added to the data generating process respectively. They also performed decently when selection bias is present, which might be interesting for observational studies where treatment randomization can't always be assured. In terms of dimensionality, performance decreases in the number of regressors, but keeps up fairly well in large samples. As an application the Lalonde (1986) data set was reconsidered in identifying treatment effects within different subgroups. Workers around 30 years old having a higher degree of eduction seem to profit the most from the NSW jobmarket program. Furthermore, workers on the lower side of income before treatment experienced higher treatment effects from the jobmarket training. Because of the good performance in identifying heterogeneity, causal forests seem to be a good tool in evaluating the effectiveness of programs for different subgroups. After all causal forests allow for a more precise evaluation, i.e. if some desired target group has been addressed, rather than only estimating the Average Treatment Effect of the whole sample.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e662a159",
   "metadata": {},
   "source": [
    "## References <a id=\"references\"></a>\n",
    "\n",
    "* **Athey & Imbens (2015).** [Recursive partitioning for heterogeneous causal effects](https://www.pnas.org/content/113/27/7353). Colloquium Paper.\n",
    "\n",
    "\n",
    "* **Athey & Wager (2015).** [Estimation and Inference of Heterogeneous Treatment Effects using Random Forests](https://arxiv.org/abs/1510.04342). \n",
    "\n",
    "\n",
    "* **Athey & Wager (2019).** [Estimating Treatment Effects with Causal Forests: An Application](https://www.gsb.stanford.edu/faculty-research/working-papers/estimating-treatment-effects-causal-forests-application). Working Paper No. 3786. \n",
    "\n",
    "\n",
    "* **Athey, Wager, Hadad, Klosin, Muhelbach, Nie & Schaelling (2020).** [Tutorial: Estimation of Heterogeneous Treatment Effects](https://gsbdbi.github.io/ml_tutorial/hte_tutorial/hte_tutorial.html). Tutorial for “Machine Learning and Causal Inference” class.\n",
    "\n",
    "\n",
    "* **Cunningham (2021).** [Causal Inference: The Mixtape](https://mixtape.scunning.com). Yale University Press.\n",
    "\n",
    "\n",
    "* **Dehejia & Wahba (1998).** [Propensity Score Matching Methods for Non-experimental Causal Studies](https://www.nber.org/papers/w6829). NBER Working Paper 6829.\n",
    "\n",
    "\n",
    "* **Farbmacher, Kögel & Spindler (2019).** [Heterogeneous Effects of Poverty on Cognition](https://www.mpisoc.mpg.de/en/social-policy-mea/publications/detail/publication/heterogeneous-effects-of-poverty-on-cognition/). MEA Discussion Paper (06-2019).\n",
    "\n",
    "\n",
    "* **Hastie, James, Witten & Tibshirani (2013).** An Introduction to Statistical Learning: with Applications in R. Springer Texts in Statistics.\n",
    "\n",
    "\n",
    "\n",
    "* **Hitsch & Misra (2018).** [Heterogeneous Treatment Effects and Optimal Targeting Policy Evaluation](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3111957). Randomized Social Experiments eJournal (2018).\n",
    "\n",
    "\n",
    "* **Lalonde (1986).** [Evaluating the Econometric Evaluations of Training Programs with Experimental Data](https://www.jstor.org/stable/1806062). American Economic Review 76 (4): 604–20.\n",
    "\n",
    "\n",
    "* **Powers, Qian, Jung, Schuler, Shah, Hastie & Tibshirani (2017).** [Some methods for heterogeneous treatment effect estimation in high-dimensions](https://web.stanford.edu/~hastie/Papers/PM_Powers_SIM.pdf).Stat Med. 2018 May 20;37(11):1767-1787. \n",
    "\n",
    "\n",
    "* **Reference: Generalized Random Forest.** [grf package description](https://grf-labs.github.io/grf/reference/index.html). Github."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
