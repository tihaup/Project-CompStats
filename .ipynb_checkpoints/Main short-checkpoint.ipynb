{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e16727",
   "metadata": {},
   "source": [
    "# Final Project CompStats | Timo Haupt | SoSe 2021\n",
    "\n",
    "---\n",
    "\n",
    "# Performance of Causal Forests in Identifying Heterogeneous Treatment Effects\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bb2ddf",
   "metadata": {},
   "source": [
    "**Importing Packages:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89a0afae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'grf' was built under R version 3.6.3\""
     ]
    }
   ],
   "source": [
    "suppressMessages(library(grf))\n",
    "suppressMessages(library(FNN))\n",
    "suppressMessages(library(MASS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93360557",
   "metadata": {},
   "source": [
    "**Importing Functions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad0ba9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "source(\"material/auxiliary.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42c2b22",
   "metadata": {},
   "source": [
    "## Structure\n",
    "\n",
    "[**1. Theoretical Discussion**](#theory)\n",
    "   * [Causal Tree](#tree)\n",
    "   * [Treatment Effect Estimation](#treatment)\n",
    "   * [Causal Forest](#forest)\n",
    "    \n",
    "[**2. Simulation Study**](#simulation)\n",
    "   * [Data Generating Process (Treatment Effect Heterogeneity)](#dgp)\n",
    "   * [Performance Measure](#performance)\n",
    "   * [Variations](#simstudy)\n",
    "\n",
    "**3. Application**\n",
    "   * Data: LaLonde\n",
    "   * Results Deijiha\n",
    "   * Results Causal Forest\n",
    "\n",
    "**4. Conclusion**\n",
    "\n",
    "[**5. References**](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f454cb94",
   "metadata": {},
   "source": [
    "## 1.) Theoretical Discussion<a id=\"theory\"></a>\n",
    "\n",
    "This first section introduces the two analyzed estimation methods, Causal Forest and Causal KNN, and describes how treatment estimation is conducted. The main problem in settings dealing with causality and inference is the missing counterfactual. Particularly in estimating treatment effects it's only possible to observe an individual with treatment, $Y_i^{(1)}$, or without treatment, $Y_i^{(0)}$, but never both. Therefore, we are in the Potential Outcome Framework where we \"posit the existence of potential outcomes $Y_i^{(1)}$ and $Y_i^{(0)}$ corresponding respectively to\n",
    "the response the $i$-th subject would have experienced with and without the treatment\" (Athey/Wager, 2015).\n",
    "\n",
    "Both introduced methods, Causal Forest and Causal KNN, try to find these potential outcomes by some sort of matching algorithm in order to estimate the treatment effect \n",
    "$$\\tau(x) = \\mathbb{E}\\left[Y_i^{(1)} - Y_i^{(0)} \\mid X_i = x\\right] $$\n",
    "\n",
    "One essential assumption we need to impose in order to theoretically justify both methods is unconfoundedness, i.e. \"treatment assignment $W_i$ is independent of the potential outcomes for $Y_i$ conditional on $X_i$\" (Athey & Wager 2015).\n",
    "\n",
    "$$\\left \\{Y_i^{(1)}, Y_i^{(0)} \\right \\} \\perp\\!\\!\\!\\perp W_i \\mid X_i $$\n",
    "\n",
    "The idea is that, if unconfoundedness holds, \"we can treat nearby observations in x-space as having come from a\n",
    "randomized experiment; thus, nearest-neighbor matching and other local methods will in general be consistent for $\\tau(x)$\" (Athey & Wager 2015)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec4f3e6",
   "metadata": {},
   "source": [
    "### Causal Tree<a id=\"tree\"></a>\n",
    "\n",
    "* Causal Trees are very similiar to Random Trees. \n",
    "\n",
    "* Difference: rather than predicting outcome $Y$, they predict treatment effects\n",
    "\n",
    "* \"splitting rule that maximizes i2Rk ^\u001c",
    " (Xi)2, which maximizes the variance of the predicted treatment effects ^\u001c",
    " (Xi) across the observations in the two new leaves. This splitting rule is feasible given the data and mimics the approach that would be used if the treatment effect was observed.\" (Hitsch Misra)\n",
    "\n",
    "* \"the algorithm seeks to maximize the treatment effect heterogeneity across partitions at every tree-splitting step\" (Farbmacher)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32dbb24",
   "metadata": {},
   "source": [
    "### Treatment Effect Estimation<a id=\"treatment\"></a>\n",
    "\n",
    "\n",
    "Let's take some $x \\in R_k$ where $R_k$ is some leaf of the Causal Forest and define $N_k(w)$ as the number of observations in the leaf $R_k$ with treatment status $w \\in \\{0,1\\}$. The Conditional Average Treatment Effect is then estimated \"based on the mean difference between the outcome levels of the treated and untreated units\" which are in the same leaf $R_k$ by \n",
    "\n",
    "$$ \\hat{\\tau}(x) = \\hat{\\tau}_{R_k} = \\frac{1}{N_k(1)} \\sum_{i \\in R_k(1)} Y_i-\\frac{1}{N_k(0)} \\sum_{i \\in R_k(0)} Y_i  $$\n",
    "So, the Causal Forest does some sort of matching by recursively partitioning the predictor space and then matching treated and untreated observations that have fallen in the same leaf (see e.g. Hitsch & Misra 2018 and Athey & Wager 2015).\n",
    "\n",
    "* Basically, we have for each individual $i$ with characteristics $x$ some specific treatment effect. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf6d4df",
   "metadata": {},
   "source": [
    "### Causal Forest<a id=\"forest\"></a>\n",
    "\n",
    "* \"Finally, given a procedure for generating a single causal tree, a causal forest generates an ensemble of B such trees, each of which outputs an estimate $\\hat{\\tau}_b(x)$. The forest then aggregates their predictions by averaging them: $\\hat{\\tau}(x) = \\frac{1}{B} \\sum_{b=1}^B \\hat{\\tau}_b(x)$\" (Athey Wager 2015)\n",
    "\n",
    "* I will go with the default of $B=2000$ causal trees per causal forest.\n",
    "\n",
    "* Advantage of Causal Forest: \"In practice, this aggregation scheme helps reduce variance and smooths sharp decision boundaries\" (Athey Wager 2015)\n",
    "\n",
    "**Honest Splitting Rule**\n",
    "\n",
    "* \"Double-sample trees split the available training data into two parts: one half for estimating the desired response inside each leaf, and another half for placing splits.\"\n",
    "\n",
    "* \"Double-sample causal trees are defined similarly, except that for prediction we estimate ^\u001c",
    " (x) using (5) on the I sample. Following Athey and Imbens [2015], the splits of the tree are chosen by maximizing the variance of $\\tau(Xi)$\"\n",
    "\n",
    "* \"Then, it uses the J -sample to place the splits, while holding out the I-sample to do within-leaf estimation\"\n",
    "\n",
    "Athey & Wager (2015) Chapter 2.4\n",
    "\n",
    "**Advantage of CF**\n",
    "\n",
    "\"At a high level, trees and forests can be thought of as nearest neighbor methods with an\n",
    "adaptive neighborhood metric. Given a test point x, classical methods such as k-nearest\n",
    "neighbors seek the k closest points to x according to some pre-speci\f",
    "ed distance measure,\n",
    "e.g., Euclidean distance. In contrast, tree-based methods also seek to \f",
    "nd training examples\n",
    "that are close to x, but now closeness is de\f",
    "ned with respect to a decision tree, and the\n",
    "closest points to x are those that fall in the same leaf as it. The advantage of trees is that\n",
    "their leaves can be narrower along the directions where the signal is changing fast and wider\n",
    "along the other directions, potentially leading a to a substantial increase in power when the\n",
    "dimension of the feature space is even moderately large.\" \n",
    "\n",
    "\"Our causal forest estimator can be thought of as an adaptive nearest\n",
    "neighbor method, where the data determines which dimensions are most important to consider\n",
    "in selecting nearest neighbors. Such adaptivity seems essential for modern large-scale\n",
    "applications with many features.\"(Athey & Wager 2015)\n",
    "\n",
    "\"When estimating a random forest, we provide the algorithm with the set of features and the\n",
    "treatment indicator, Wi. Specifying the interactions between Xi and Wi is not be necessary\n",
    "because random forests, a non-parametric estimation method, in principle should be able to\n",
    "automatically detect any relevant interactions.\" (Farbmacher et al.)\n",
    "\n",
    "#### GRF package\n",
    "\n",
    "**Plot example Causal Tree**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c88d1",
   "metadata": {},
   "source": [
    "# 2.) Simulation Study<a id=\"simulation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33145bab",
   "metadata": {},
   "source": [
    "## Data Generating Process<a id=\"dgp\"></a>\n",
    "\n",
    "Note that the codes for the Data Generating Process and the Monte Carlo Simulation Study can be found in the auxiliary-file. The variations in the treatment effect function $\\tau(x)$ and the DGP function are inspired by Athey & Wager (2015) and Powers et al. (2017). \n",
    "\n",
    "\n",
    "$$X_{i,1}, ..., X_{i,10} \\sim \\mathcal{N}(0,1)$$\n",
    "\n",
    "$$\\beta \\in [0.5,1]^{10}$$\n",
    "\n",
    "$$Prob(W_i=1) =0.5$$\n",
    "\n",
    "$$Y_i = X \\beta + \\tau(x_i)* W_i + \\epsilon_i $$\n",
    "\n",
    "$$\\epsilon_i \\sim \\mathcal{N}(0,\\,0.1)$$\n",
    "\n",
    "**Description**\n",
    "\n",
    "The specification above displays the basic setup of the Data Generating Process. \n",
    "10 regressors are drawn from a Standard Normal Distrubtion and all $\\beta$ are evenly divided between 0.5 and 1. \n",
    "The probability of being assigned to treatment is fixed at 50% for all observations. The individual error term is also drawn from a Normal Distribution with mean zero and standard deviation of 0.1.\n",
    "All changes and additions that have been made in the Simulation Study, will be explained in greater detail as a description before each scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de094601",
   "metadata": {},
   "source": [
    "## Performance Measure<a id=\"performance\"></a>\n",
    "\n",
    "Eventhough the counterfactuals are never observed in real life data, we can take advantage of the Data Generating Process in Simulation Studies where we explicitely calculate the true treatment effect for each observation. Therefore, as Athey & Wager (2015) proposed we can use the $MSE_{\\tau}$ as a measure in order to compare the performance of the Causal Forest in different settings. I calculated the Mean Squared Error of the treatment effect as follows\n",
    "$$MSE_{\\tau} = \\frac{1}{N} \\sum_{i=1}^N{\\left( \\tau_{i}-\\hat{\\tau}_{R_k}(X_i) \\right)^{2}} $$\n",
    "\n",
    ", where $\\hat{\\tau}_{R_k}(X_i)$ are the estimated treatment effects for individuals in leaf $R_k$.\n",
    "Note that the $MSE_{\\tau}$ used in this Simulation Study differs slightly from the one proposed in the Athey and Imbens (2015) paper. They subtract $\\mathbb{E}[\\tau_i^2]$, but as they noted \"it does not affect how the criterion ranks estimators\", since $\\tau_i$ is not a Random Variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2661b0bd",
   "metadata": {},
   "source": [
    "## Monte Carlo Simulation Study - Variations<a id=\"simstudy\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559f2112",
   "metadata": {},
   "source": [
    "### Case 1(new) - Introduction of Treatment Effect Functions\n",
    "\n",
    "$(1)\\quad \\tau(x) = 0.2 $\n",
    "\n",
    "$(2)\\quad \\tau(x) = 0.1 + 0.1*\\mathbb{1}(x_1 > 0) + 0.1*\\mathbb{1}(x_2 > 0)$\n",
    "\n",
    "$(3)\\quad \\tau(x) = 0.1 + x_1*\\mathbb{1}(x_1 > 0) + x_2*\\mathbb{1}(x_2 > 0)$  \n",
    "\n",
    "$(4)\\quad \\tau(x) = 0.1 + \\sum_{i=1}^{4} \\mathbb{1}(x_i > 0)*x_i $\n",
    "\n",
    "$(5)\\quad \\tau(x) = 0.2 + x_1*x_2 $\n",
    "\n",
    "\n",
    "**Description & Result**\n",
    "\n",
    "Case 1 will be used as a benchmark where the basic setup is considered. The different treatment scenarios are depicted above. \n",
    "In the first scenario $(1)$ there is only a single treatment effect independent of individuals' characteristics. Treatment scenario $(2)$ introduces some simple treatment effect heterogeneity, that is treatment effect increases if an individual has positive values in its' $X_1$ and $X_2$ characteristics respectively. Each positive value increases the magnitude by the mean treatment effect of 0.1. \n",
    "In treatment scenario $(3)$ complexity of heterogeneity is increased, such that the magnitude of treatment depends on the values of $X_1$ and $X_2$. So, treatment effect is even heterogeneous within $X_1$ and $X_2$. Higher positive values of these variables imply a higher treatment effect. \n",
    "Scenario $(4)$ adds two more regressors in the treatment effect function. \n",
    "Scenario $(5)$ introduces an interaction term in $\\tau(x)$. Since $X$ are standard normally distributed, around half of the draws from $X_1$ and $X_2$ are negative, implying an even higher degree of treatment variation.\n",
    "\n",
    "It can be observed that the higher the number of observations, the smaller the Mean Squared Error. This holds true for all successive applications. This is theoretically justified, since with a higher number of observations the trees can perform more splits per tree without reaching the boundary of minimal observations per leaf. \n",
    "Interesting is that the $MSE_{\\tau}$ almost doesn't differ between homogeneous and a very simple treatment effect, $(1)$ and $(2)$. This result is quite remarkable and shows that Causal Forests seem to be quite good at matching observations with a simple heterogeneity structure. It should be noted that Powers et al. (2017) find some striking differences between scenarios 1 and 2 in their paper which come closest to my Treatment Scenarios $(1)$ and $(2)$. One reason might be that Powers et al. (2017) draw their regressors mixed from Standard Normal and Bernoulli distributions.\n",
    "Since Scenarios $(3)$ to $(4)$ imply a higher degree of variation in individual treatment effects, it is obvious that the $MSE_{\\tau}$ are much higher compared to the previous scenarios. Even for a large sample the estimated $MSE_{\\tau}$ can't keep up. These results are consistent though with the ones from Table S1 (Appendix) in Athey and Imbens (2015)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "869a6456",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4264b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Application</th><th scope=col>N = 100</th><th scope=col>N = 150</th><th scope=col>N = 250</th><th scope=col>N = 500</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Treatment 1</td><td>0.270      </td><td>0.140      </td><td>0.098      </td><td>0.059      </td></tr>\n",
       "\t<tr><td>Treatment 2</td><td>0.203      </td><td>0.152      </td><td>0.109      </td><td>0.081      </td></tr>\n",
       "\t<tr><td>Treatment 3</td><td>0.833      </td><td>0.698      </td><td>0.565      </td><td>0.382      </td></tr>\n",
       "\t<tr><td>Treatment 4</td><td>1.423      </td><td>1.271      </td><td>1.061      </td><td>0.784      </td></tr>\n",
       "\t<tr><td>Treatment 5</td><td>1.188      </td><td>1.167      </td><td>1.061      </td><td>0.996      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Application & N = 100 & N = 150 & N = 250 & N = 500\\\\\n",
       "\\hline\n",
       "\t Treatment 1 & 0.270       & 0.140       & 0.098       & 0.059      \\\\\n",
       "\t Treatment 2 & 0.203       & 0.152       & 0.109       & 0.081      \\\\\n",
       "\t Treatment 3 & 0.833       & 0.698       & 0.565       & 0.382      \\\\\n",
       "\t Treatment 4 & 1.423       & 1.271       & 1.061       & 0.784      \\\\\n",
       "\t Treatment 5 & 1.188       & 1.167       & 1.061       & 0.996      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Application | N = 100 | N = 150 | N = 250 | N = 500 |\n",
       "|---|---|---|---|---|\n",
       "| Treatment 1 | 0.270       | 0.140       | 0.098       | 0.059       |\n",
       "| Treatment 2 | 0.203       | 0.152       | 0.109       | 0.081       |\n",
       "| Treatment 3 | 0.833       | 0.698       | 0.565       | 0.382       |\n",
       "| Treatment 4 | 1.423       | 1.271       | 1.061       | 0.784       |\n",
       "| Treatment 5 | 1.188       | 1.167       | 1.061       | 0.996       |\n",
       "\n"
      ],
      "text/plain": [
       "  Application N = 100 N = 150 N = 250 N = 500\n",
       "1 Treatment 1 0.270   0.140   0.098   0.059  \n",
       "2 Treatment 2 0.203   0.152   0.109   0.081  \n",
       "3 Treatment 3 0.833   0.698   0.565   0.382  \n",
       "4 Treatment 4 1.423   1.271   1.061   0.784  \n",
       "5 Treatment 5 1.188   1.167   1.061   0.996  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simulation(p=10,numsim=100,regressors=\"nocorr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cdfe72",
   "metadata": {},
   "source": [
    "### Case 2(new) - Polynomials and Interactions added to DGP\n",
    "\n",
    "$(1) \\quad X_{i,9} = X_{i,1}^2 \\quad $ and $\\quad X_{i,10} = X_{i,2}^2$\n",
    "\n",
    "$(2) \\quad X_{i,2} = X_{i,1}^2$\n",
    "\n",
    "$(3) \\quad X_{i,10} = X_{i,1}*X_{i,2}$\n",
    "\n",
    "**Description & Result**\n",
    "\n",
    "In Case 2 different changes in the Data Generating Process have been made. In scenario $(1)$ quadratic transformations of $X_1$ and $X_2$ have been added in the DGP function. Scenario $(2)$ differs in that the quadratic transformation of $X_1$ displaces the $X_2$ variable, implying that only $X_1$ and it's second degree polynomial determine treatment heterogeneity. $(3)$ depicts the scenario with an additional interaction term between $X_1$ and $X_2$ in the DGP.\n",
    "\n",
    "\n",
    "\n",
    "Causal Forests seem to make pretty good treatment predictions compared to Case 1 without any additional interactions or polynomials. Since it's a non-parametric method and therefore don't make explicit assumptions about the underlying functional form, this result seems to be consistent with the theoretical properties.\n",
    "Adding the interaction term between $X_1$ and $X_2$ into the DGP makes the Causal Forest perform the best within all scenarios where polynomials or interactions have been considered. \n",
    "As Hitsch and Misra (2018) state it, this makes sense, since Causal Forest is \"a non-parametric estimation method, [and] in principle should be able to automatically detect any relevant interactions\".\n",
    "The good performance compared to Case 1 could also be explained by the fewer number of total regressors, since either one or two regressors basically include the same information as $X_1$ and/or $X_2$. The performance with fewer regressors will also be discussed in Case 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d3e03c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Application</th><th scope=col>N = 100</th><th scope=col>N = 150</th><th scope=col>N = 250</th><th scope=col>N = 500</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Treatment 1</td><td>0.237      </td><td>0.187      </td><td>0.117      </td><td>0.072      </td></tr>\n",
       "\t<tr><td>Treatment 2</td><td>0.194      </td><td>0.178      </td><td>0.103      </td><td>0.072      </td></tr>\n",
       "\t<tr><td>Treatment 3</td><td>0.919      </td><td>0.742      </td><td>0.539      </td><td>0.360      </td></tr>\n",
       "\t<tr><td>Treatment 4</td><td>1.517      </td><td>1.360      </td><td>1.087      </td><td>0.783      </td></tr>\n",
       "\t<tr><td>Treatment 5</td><td>1.307      </td><td>1.208      </td><td>1.104      </td><td>0.988      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Application & N = 100 & N = 150 & N = 250 & N = 500\\\\\n",
       "\\hline\n",
       "\t Treatment 1 & 0.237       & 0.187       & 0.117       & 0.072      \\\\\n",
       "\t Treatment 2 & 0.194       & 0.178       & 0.103       & 0.072      \\\\\n",
       "\t Treatment 3 & 0.919       & 0.742       & 0.539       & 0.360      \\\\\n",
       "\t Treatment 4 & 1.517       & 1.360       & 1.087       & 0.783      \\\\\n",
       "\t Treatment 5 & 1.307       & 1.208       & 1.104       & 0.988      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Application | N = 100 | N = 150 | N = 250 | N = 500 |\n",
       "|---|---|---|---|---|\n",
       "| Treatment 1 | 0.237       | 0.187       | 0.117       | 0.072       |\n",
       "| Treatment 2 | 0.194       | 0.178       | 0.103       | 0.072       |\n",
       "| Treatment 3 | 0.919       | 0.742       | 0.539       | 0.360       |\n",
       "| Treatment 4 | 1.517       | 1.360       | 1.087       | 0.783       |\n",
       "| Treatment 5 | 1.307       | 1.208       | 1.104       | 0.988       |\n",
       "\n"
      ],
      "text/plain": [
       "  Application N = 100 N = 150 N = 250 N = 500\n",
       "1 Treatment 1 0.237   0.187   0.117   0.072  \n",
       "2 Treatment 2 0.194   0.178   0.103   0.072  \n",
       "3 Treatment 3 0.919   0.742   0.539   0.360  \n",
       "4 Treatment 4 1.517   1.360   1.087   0.783  \n",
       "5 Treatment 5 1.307   1.208   1.104   0.988  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simulation(p=10,numsim=100,regressors=\"poly1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4ab670d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Application</th><th scope=col>N = 100</th><th scope=col>N = 150</th><th scope=col>N = 250</th><th scope=col>N = 500</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Treatment 1</td><td> 0.233     </td><td> 0.152     </td><td> 0.111     </td><td>0.073      </td></tr>\n",
       "\t<tr><td>Treatment 2</td><td> 0.227     </td><td> 0.150     </td><td> 0.120     </td><td>0.068      </td></tr>\n",
       "\t<tr><td>Treatment 3</td><td> 3.037     </td><td> 2.454     </td><td> 1.534     </td><td>0.850      </td></tr>\n",
       "\t<tr><td>Treatment 4</td><td> 3.614     </td><td> 3.075     </td><td> 2.305     </td><td>1.343      </td></tr>\n",
       "\t<tr><td>Treatment 5</td><td>13.124     </td><td>12.619     </td><td>10.595     </td><td>7.334      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Application & N = 100 & N = 150 & N = 250 & N = 500\\\\\n",
       "\\hline\n",
       "\t Treatment 1 &  0.233      &  0.152      &  0.111      & 0.073      \\\\\n",
       "\t Treatment 2 &  0.227      &  0.150      &  0.120      & 0.068      \\\\\n",
       "\t Treatment 3 &  3.037      &  2.454      &  1.534      & 0.850      \\\\\n",
       "\t Treatment 4 &  3.614      &  3.075      &  2.305      & 1.343      \\\\\n",
       "\t Treatment 5 & 13.124      & 12.619      & 10.595      & 7.334      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Application | N = 100 | N = 150 | N = 250 | N = 500 |\n",
       "|---|---|---|---|---|\n",
       "| Treatment 1 |  0.233      |  0.152      |  0.111      | 0.073       |\n",
       "| Treatment 2 |  0.227      |  0.150      |  0.120      | 0.068       |\n",
       "| Treatment 3 |  3.037      |  2.454      |  1.534      | 0.850       |\n",
       "| Treatment 4 |  3.614      |  3.075      |  2.305      | 1.343       |\n",
       "| Treatment 5 | 13.124      | 12.619      | 10.595      | 7.334       |\n",
       "\n"
      ],
      "text/plain": [
       "  Application N = 100 N = 150 N = 250 N = 500\n",
       "1 Treatment 1  0.233   0.152   0.111  0.073  \n",
       "2 Treatment 2  0.227   0.150   0.120  0.068  \n",
       "3 Treatment 3  3.037   2.454   1.534  0.850  \n",
       "4 Treatment 4  3.614   3.075   2.305  1.343  \n",
       "5 Treatment 5 13.124  12.619  10.595  7.334  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simulation(p=10,numsim=100,regressors=\"poly2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02548634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Application</th><th scope=col>N = 100</th><th scope=col>N = 150</th><th scope=col>N = 250</th><th scope=col>N = 500</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Treatment 1</td><td>0.206      </td><td>0.157      </td><td>0.099      </td><td>0.076      </td></tr>\n",
       "\t<tr><td>Treatment 2</td><td>0.294      </td><td>0.194      </td><td>0.118      </td><td>0.073      </td></tr>\n",
       "\t<tr><td>Treatment 3</td><td>0.835      </td><td>0.683      </td><td>0.512      </td><td>0.348      </td></tr>\n",
       "\t<tr><td>Treatment 4</td><td>1.517      </td><td>1.321      </td><td>1.025      </td><td>0.750      </td></tr>\n",
       "\t<tr><td>Treatment 5</td><td>1.031      </td><td>0.926      </td><td>0.715      </td><td>0.481      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Application & N = 100 & N = 150 & N = 250 & N = 500\\\\\n",
       "\\hline\n",
       "\t Treatment 1 & 0.206       & 0.157       & 0.099       & 0.076      \\\\\n",
       "\t Treatment 2 & 0.294       & 0.194       & 0.118       & 0.073      \\\\\n",
       "\t Treatment 3 & 0.835       & 0.683       & 0.512       & 0.348      \\\\\n",
       "\t Treatment 4 & 1.517       & 1.321       & 1.025       & 0.750      \\\\\n",
       "\t Treatment 5 & 1.031       & 0.926       & 0.715       & 0.481      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Application | N = 100 | N = 150 | N = 250 | N = 500 |\n",
       "|---|---|---|---|---|\n",
       "| Treatment 1 | 0.206       | 0.157       | 0.099       | 0.076       |\n",
       "| Treatment 2 | 0.294       | 0.194       | 0.118       | 0.073       |\n",
       "| Treatment 3 | 0.835       | 0.683       | 0.512       | 0.348       |\n",
       "| Treatment 4 | 1.517       | 1.321       | 1.025       | 0.750       |\n",
       "| Treatment 5 | 1.031       | 0.926       | 0.715       | 0.481       |\n",
       "\n"
      ],
      "text/plain": [
       "  Application N = 100 N = 150 N = 250 N = 500\n",
       "1 Treatment 1 0.206   0.157   0.099   0.076  \n",
       "2 Treatment 2 0.294   0.194   0.118   0.073  \n",
       "3 Treatment 3 0.835   0.683   0.512   0.348  \n",
       "4 Treatment 4 1.517   1.321   1.025   0.750  \n",
       "5 Treatment 5 1.031   0.926   0.715   0.481  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simulation(p=10,numsim=100,regressors=\"interaction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfe9c06",
   "metadata": {},
   "source": [
    "### Case 3 - Correlation between Regressors\n",
    "\n",
    "$(1) \\quad \\rho_{j,k} = 0.5 \\qquad \\forall j,k = \\{1,...,10\\} \\quad s.t. \\quad j \\ne k  $\n",
    "\n",
    "$(2) \\quad \\rho_{1,2} = 0.9$\n",
    "\n",
    "**Description & Result**\n",
    "\n",
    "Case 3 deals with correlation between regressors. In scenario $(1)$ all regressors are moderately correlated with each other by $\\rho = 0.5$ and in $(2)$ only the two regressors that influence treatment heterogeneity are highly correlated by $\\rho = 0.9$. This exploration might be interesting for economic settings with some sorts of trends, where variables have some influence of each other.\n",
    "\n",
    "Except for the first treatment setting, in both correlation scenarios Causal Forest performs a little bit wors for small samples, but improves significantly with large samples. These findings are interesting in that Matching Estimators, Causal Forest in particular, seem to handle the problem of correlation between regressors very well, especially in large samples. **Theoretical Explanation?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0f960f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Application</th><th scope=col>N = 100</th><th scope=col>N = 150</th><th scope=col>N = 250</th><th scope=col>N = 500</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Treatment 1</td><td>0.315      </td><td>0.201      </td><td>0.103      </td><td>0.060      </td></tr>\n",
       "\t<tr><td>Treatment 2</td><td>0.287      </td><td>0.177      </td><td>0.109      </td><td>0.065      </td></tr>\n",
       "\t<tr><td>Treatment 3</td><td>1.096      </td><td>0.827      </td><td>0.579      </td><td>0.365      </td></tr>\n",
       "\t<tr><td>Treatment 4</td><td>2.538      </td><td>1.850      </td><td>1.334      </td><td>0.775      </td></tr>\n",
       "\t<tr><td>Treatment 5</td><td>1.523      </td><td>1.323      </td><td>1.145      </td><td>0.913      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Application & N = 100 & N = 150 & N = 250 & N = 500\\\\\n",
       "\\hline\n",
       "\t Treatment 1 & 0.315       & 0.201       & 0.103       & 0.060      \\\\\n",
       "\t Treatment 2 & 0.287       & 0.177       & 0.109       & 0.065      \\\\\n",
       "\t Treatment 3 & 1.096       & 0.827       & 0.579       & 0.365      \\\\\n",
       "\t Treatment 4 & 2.538       & 1.850       & 1.334       & 0.775      \\\\\n",
       "\t Treatment 5 & 1.523       & 1.323       & 1.145       & 0.913      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Application | N = 100 | N = 150 | N = 250 | N = 500 |\n",
       "|---|---|---|---|---|\n",
       "| Treatment 1 | 0.315       | 0.201       | 0.103       | 0.060       |\n",
       "| Treatment 2 | 0.287       | 0.177       | 0.109       | 0.065       |\n",
       "| Treatment 3 | 1.096       | 0.827       | 0.579       | 0.365       |\n",
       "| Treatment 4 | 2.538       | 1.850       | 1.334       | 0.775       |\n",
       "| Treatment 5 | 1.523       | 1.323       | 1.145       | 0.913       |\n",
       "\n"
      ],
      "text/plain": [
       "  Application N = 100 N = 150 N = 250 N = 500\n",
       "1 Treatment 1 0.315   0.201   0.103   0.060  \n",
       "2 Treatment 2 0.287   0.177   0.109   0.065  \n",
       "3 Treatment 3 1.096   0.827   0.579   0.365  \n",
       "4 Treatment 4 2.538   1.850   1.334   0.775  \n",
       "5 Treatment 5 1.523   1.323   1.145   0.913  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simulation(p=10,numsim=100,regressors=\"corr1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b31bff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation(p=10,numsim=100,regressors=\"corr2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2976d0ed",
   "metadata": {},
   "source": [
    "### Case 4 - Treatment variables don't influence Y\n",
    "\n",
    "$(1) \\quad \\beta_1, \\beta_2 = 0$\n",
    "\n",
    "**Description & Result**\n",
    "\n",
    "In Case 2 both $X_1$ and $X_2$ influence treatment effect heterogeneity, but don't have any influence on the output variable $Y$. Since the number of regressors has an impact of how well the estimation method performs, I conduct this analysis with 12 regressors (minus the two regressors with $\\beta = 0$) in order to assure comparability to Case 1 with 10 regressors in total. \n",
    "\n",
    "Causal Forests perform very similiar to the scenario where $\\beta_1, \\beta_2 \\neq 0$, indicating that they are able to detect heterogeneity based on variables that don't influence $Y$. This makes sense from a theoretical point of view, since the splits of the tree are being made as to generate some high level of treatment variation between the split directions. Therefore, detection of treatment heterogeneity works as long as these variables are included in the dataset, eventhough they don't influence $Y$ directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916fb469",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation(p=10,numsim=100,regressors=\"beta12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7ed438",
   "metadata": {},
   "source": [
    "### Case 5 - Treatment Probability depends on $X$\n",
    "\n",
    "$(1) \\quad Prob(W_i = 1 \\mid x_1>0) = 0.75 \\quad $ and $\\quad Prob(W_i = 1 \\mid x_1<0) = 0.25 $\n",
    "\n",
    "**Description & Result**\n",
    "\n",
    "Before Marginal Treatment Probability has been fixed at 0.5 for all individuals. In this scenario Selection Bias will be introduced. Those individuals profiting more from Treatment, i.e. individuals with positive values in the $X_1$ characteristic, are more likely to be assigned to Treatment. Treatment Probability for $X_1 > 0$ is 0.75, whereas Treatment Probability for $X_1 < 0$ is only 0.25. The analysis of this case has importance in observational studies where randomization in treatment assignment can often not be assured.  \n",
    "\n",
    "We see a slight increase in $MSE_{\\tau}$ compared to Case 1 for 100 and 150 observations, but Causal Forests perform relatively worse for 500 observations, indicating that the performance with selection bias cannot quite keep up in large scale samples, where both methods have usually their largest improvements, as seen in previous cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e016e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation(p=10,numsim=100,regressors=\"selectionbias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3e4c2c",
   "metadata": {},
   "source": [
    "### Case 6 - Number of Regressors\n",
    "\n",
    "$(1)-(4) \\quad p \\in \\{4,20,50,100\\}$\n",
    "\n",
    "**Description & Result**\n",
    "\n",
    "In this final scenario performance with a different number of regressors is compared. Number of regressors is varied between 4 and 100. This comparison is interesting in applications where the researcher might have a dataset containing a lot of different characteristics. \n",
    "\n",
    "I find that the overall performance decreases if more regressors are added. An interesting finding is that the KNN methods can't really improve their performance over the number of observations, whereas Causal Forest signficantly decreases $MSE_{\\tau}$ going from 100 to 500 observations. So, even if one has a high dimensional data set, this simulation study shows that if the number of observations is quite large the Causal Forest will perform quite well. THe relatively well performance of the Causal Forest in high dimensional space can be explained theoretically by it's variable selection feature. By training the trees with only the most \"important\" variables, only a couple variables will be selected by the Causal Tree overall. On the other hand, KNN tries to find the closest neighbors in the Euclidean Space and is therefore not reducing dimensionality. \n",
    "\n",
    "* Economic Setting: Higher Dimensional Datasets, Purpose?\n",
    "\n",
    "* **Warum wird die Treatment Vorhersage schlechter je mehr Regressoren verwendet werden???**\n",
    "\n",
    "* **Intuition**\n",
    "\n",
    "* CF auch im high dimensional space better, since it performs a kind of variable selection, by training the trees with only the most important variables!\n",
    "\n",
    "* no big increase in MSE going from 50 to 100 regressors. Good sign for Application purposes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e191f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation(p=4,numsim=100,regressors=\"nocorr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c36e7f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Application</th><th scope=col>N = 100</th><th scope=col>N = 150</th><th scope=col>N = 250</th><th scope=col>N = 500</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Treatment 1</td><td>0.541      </td><td>0.425      </td><td>0.204      </td><td>0.122      </td></tr>\n",
       "\t<tr><td>Treatment 2</td><td>0.479      </td><td>0.372      </td><td>0.221      </td><td>0.100      </td></tr>\n",
       "\t<tr><td>Treatment 3</td><td>0.881      </td><td>0.865      </td><td>0.780      </td><td>0.611      </td></tr>\n",
       "\t<tr><td>Treatment 4</td><td>2.343      </td><td>1.550      </td><td>1.356      </td><td>1.217      </td></tr>\n",
       "\t<tr><td>Treatment 5</td><td>1.362      </td><td>1.147      </td><td>1.130      </td><td>1.123      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Application & N = 100 & N = 150 & N = 250 & N = 500\\\\\n",
       "\\hline\n",
       "\t Treatment 1 & 0.541       & 0.425       & 0.204       & 0.122      \\\\\n",
       "\t Treatment 2 & 0.479       & 0.372       & 0.221       & 0.100      \\\\\n",
       "\t Treatment 3 & 0.881       & 0.865       & 0.780       & 0.611      \\\\\n",
       "\t Treatment 4 & 2.343       & 1.550       & 1.356       & 1.217      \\\\\n",
       "\t Treatment 5 & 1.362       & 1.147       & 1.130       & 1.123      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Application | N = 100 | N = 150 | N = 250 | N = 500 |\n",
       "|---|---|---|---|---|\n",
       "| Treatment 1 | 0.541       | 0.425       | 0.204       | 0.122       |\n",
       "| Treatment 2 | 0.479       | 0.372       | 0.221       | 0.100       |\n",
       "| Treatment 3 | 0.881       | 0.865       | 0.780       | 0.611       |\n",
       "| Treatment 4 | 2.343       | 1.550       | 1.356       | 1.217       |\n",
       "| Treatment 5 | 1.362       | 1.147       | 1.130       | 1.123       |\n",
       "\n"
      ],
      "text/plain": [
       "  Application N = 100 N = 150 N = 250 N = 500\n",
       "1 Treatment 1 0.541   0.425   0.204   0.122  \n",
       "2 Treatment 2 0.479   0.372   0.221   0.100  \n",
       "3 Treatment 3 0.881   0.865   0.780   0.611  \n",
       "4 Treatment 4 2.343   1.550   1.356   1.217  \n",
       "5 Treatment 5 1.362   1.147   1.130   1.123  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### NEW\n",
    "\n",
    "simulation(p=20,numsim=10,regressors=\"nocorr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93813d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Application</th><th scope=col>N = 100</th><th scope=col>N = 150</th><th scope=col>N = 250</th><th scope=col>N = 500</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Treatment 1</td><td>0.665      </td><td>0.859      </td><td>0.625      </td><td>0.297      </td></tr>\n",
       "\t<tr><td>Treatment 2</td><td>0.550      </td><td>0.707      </td><td>0.663      </td><td>0.367      </td></tr>\n",
       "\t<tr><td>Treatment 3</td><td>1.808      </td><td>1.498      </td><td>1.087      </td><td>0.807      </td></tr>\n",
       "\t<tr><td>Treatment 4</td><td>3.714      </td><td>2.517      </td><td>1.898      </td><td>1.538      </td></tr>\n",
       "\t<tr><td>Treatment 5</td><td>1.913      </td><td>1.932      </td><td>1.851      </td><td>1.318      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Application & N = 100 & N = 150 & N = 250 & N = 500\\\\\n",
       "\\hline\n",
       "\t Treatment 1 & 0.665       & 0.859       & 0.625       & 0.297      \\\\\n",
       "\t Treatment 2 & 0.550       & 0.707       & 0.663       & 0.367      \\\\\n",
       "\t Treatment 3 & 1.808       & 1.498       & 1.087       & 0.807      \\\\\n",
       "\t Treatment 4 & 3.714       & 2.517       & 1.898       & 1.538      \\\\\n",
       "\t Treatment 5 & 1.913       & 1.932       & 1.851       & 1.318      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Application | N = 100 | N = 150 | N = 250 | N = 500 |\n",
       "|---|---|---|---|---|\n",
       "| Treatment 1 | 0.665       | 0.859       | 0.625       | 0.297       |\n",
       "| Treatment 2 | 0.550       | 0.707       | 0.663       | 0.367       |\n",
       "| Treatment 3 | 1.808       | 1.498       | 1.087       | 0.807       |\n",
       "| Treatment 4 | 3.714       | 2.517       | 1.898       | 1.538       |\n",
       "| Treatment 5 | 1.913       | 1.932       | 1.851       | 1.318       |\n",
       "\n"
      ],
      "text/plain": [
       "  Application N = 100 N = 150 N = 250 N = 500\n",
       "1 Treatment 1 0.665   0.859   0.625   0.297  \n",
       "2 Treatment 2 0.550   0.707   0.663   0.367  \n",
       "3 Treatment 3 1.808   1.498   1.087   0.807  \n",
       "4 Treatment 4 3.714   2.517   1.898   1.538  \n",
       "5 Treatment 5 1.913   1.932   1.851   1.318  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### NEW\n",
    "\n",
    "simulation(p=50,numsim=10,regressors=\"nocorr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a0b468f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Application</th><th scope=col>N = 100</th><th scope=col>N = 150</th><th scope=col>N = 250</th><th scope=col>N = 500</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Treatment 1</td><td>1.209      </td><td>2.166      </td><td>1.225      </td><td>0.473      </td></tr>\n",
       "\t<tr><td>Treatment 2</td><td>1.431      </td><td>2.530      </td><td>1.530      </td><td>0.616      </td></tr>\n",
       "\t<tr><td>Treatment 3</td><td>1.917      </td><td>2.186      </td><td>2.335      </td><td>1.041      </td></tr>\n",
       "\t<tr><td>Treatment 4</td><td>4.147      </td><td>3.515      </td><td>1.880      </td><td>1.513      </td></tr>\n",
       "\t<tr><td>Treatment 5</td><td>4.130      </td><td>2.020      </td><td>1.972      </td><td>1.445      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Application & N = 100 & N = 150 & N = 250 & N = 500\\\\\n",
       "\\hline\n",
       "\t Treatment 1 & 1.209       & 2.166       & 1.225       & 0.473      \\\\\n",
       "\t Treatment 2 & 1.431       & 2.530       & 1.530       & 0.616      \\\\\n",
       "\t Treatment 3 & 1.917       & 2.186       & 2.335       & 1.041      \\\\\n",
       "\t Treatment 4 & 4.147       & 3.515       & 1.880       & 1.513      \\\\\n",
       "\t Treatment 5 & 4.130       & 2.020       & 1.972       & 1.445      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Application | N = 100 | N = 150 | N = 250 | N = 500 |\n",
       "|---|---|---|---|---|\n",
       "| Treatment 1 | 1.209       | 2.166       | 1.225       | 0.473       |\n",
       "| Treatment 2 | 1.431       | 2.530       | 1.530       | 0.616       |\n",
       "| Treatment 3 | 1.917       | 2.186       | 2.335       | 1.041       |\n",
       "| Treatment 4 | 4.147       | 3.515       | 1.880       | 1.513       |\n",
       "| Treatment 5 | 4.130       | 2.020       | 1.972       | 1.445       |\n",
       "\n"
      ],
      "text/plain": [
       "  Application N = 100 N = 150 N = 250 N = 500\n",
       "1 Treatment 1 1.209   2.166   1.225   0.473  \n",
       "2 Treatment 2 1.431   2.530   1.530   0.616  \n",
       "3 Treatment 3 1.917   2.186   2.335   1.041  \n",
       "4 Treatment 4 4.147   3.515   1.880   1.513  \n",
       "5 Treatment 5 4.130   2.020   1.972   1.445  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### NEW\n",
    "\n",
    "simulation(p=100,numsim=10,regressors=\"nocorr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f37cbe0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#CF_simstudy(p=10,N=500,numsim=50,dgp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97810c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CF_simstudy(p=10,N=500,numsim=10,dgp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "594d9fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CF_simstudy(p=10,N=500,numsim=10,dgp4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e662a159",
   "metadata": {},
   "source": [
    "## References <a id=\"references\"></a>\n",
    "\n",
    "* **Athey & Imbens (2015).** [Recursive partitioning for heterogeneous causal effects](https://www.pnas.org/content/113/27/7353). Colloquium Paper.\n",
    "\n",
    "\n",
    "* **Athey & Wager (2015).** [Estimation and Inference of Heterogeneous Treatment Effects using Random Forests](https://arxiv.org/abs/1510.04342). \n",
    "\n",
    "\n",
    "* **Athey & Wager (2019a).** [Estimating Treatment Effects with Causal Forests: An Application](https://www.gsb.stanford.edu/faculty-research/working-papers/estimating-treatment-effects-causal-forests-application). Working Paper No. 3786. \n",
    "\n",
    "\n",
    "* **Athey, Wager, Hadad, Klosin, Muhelbach, Nie & Schaelling (2020).** [Tutorial: Estimation of Heterogeneous Treatment Effects](https://gsbdbi.github.io/ml_tutorial/hte_tutorial/hte_tutorial.html). Tutorial for “Machine Learning and Causal Inference” class.\n",
    "\n",
    "\n",
    "* **Farbmacher, Kögel & Spindler (2019).** [Heterogeneous Effects of Poverty on Cognition](https://www.mpisoc.mpg.de/en/social-policy-mea/publications/detail/publication/heterogeneous-effects-of-poverty-on-cognition/). MEA Discussion Paper (06-2019).\n",
    "\n",
    "\n",
    "* **Hitsch & Misra (2018).** [Heterogeneous Treatment Effects and Optimal Targeting Policy Evaluation](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3111957). Randomized Social Experiments eJournal (2018).\n",
    "\n",
    "\n",
    "* **Powers, Qian, Jung, Schuler, Shah, Hastie & Tibshirani (2017).** [Some methods for heterogeneous treatment effect estimation in high-dimensions](https://web.stanford.edu/~hastie/Papers/PM_Powers_SIM.pdf).Stat Med. 2018 May 20;37(11):1767-1787. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
